{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert G3 marks and absences into categorical variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    402\n",
      "2    287\n",
      "3    160\n",
      "4     25\n",
      "5      8\n",
      "Name: absences.x, dtype: int64\n",
      "1    490\n",
      "2    290\n",
      "3     91\n",
      "4     11\n",
      "Name: absences.y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "complete_dataset=pd.read_csv('D:\\\\student\\\\final_combined_dataset.csv')\n",
    "def marks_conversion(col):#convert marks to two categories\n",
    "    grades=list(complete_dataset[col])\n",
    "    categorical_marks=[]\n",
    "    for g in grades:\n",
    "        if g in list(range(0,10)):\n",
    "            categorical_marks.append(0)\n",
    "        if g in list(range(10,21)):\n",
    "            categorical_marks.append(1)\n",
    "    return categorical_marks\n",
    "complete_dataset['G3.x']=marks_conversion('G3.x')\n",
    "complete_dataset['G3.y']=marks_conversion('G3.y')\n",
    "def convert_absences(col_name):#convert absences into four categories\n",
    "    absents_data=list(complete_dataset[col_name])\n",
    "    #print(absents_data)\n",
    "    categorical_absences=[]\n",
    "    for a in absents_data:\n",
    "        if a in list(range(0,3)):\n",
    "            categorical_absences.append(1)\n",
    "        if a in list(range(3,9)):\n",
    "            categorical_absences.append(2)\n",
    "        if a in list(range(9,22)):\n",
    "            categorical_absences.append(3)\n",
    "        if a in list(range(22,45)):\n",
    "            categorical_absences.append(4)\n",
    "        if a in list(range(45,94)):\n",
    "            categorical_absences.append(5)\n",
    "    return categorical_absences\n",
    "complete_dataset['absences.x']=convert_absences('absences.x')\n",
    "complete_dataset['absences.y']=convert_absences('absences.y')\n",
    "print(complete_dataset['absences.x'].value_counts())\n",
    "print(complete_dataset['absences.y'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gather features and labels for both maths and portuguese subject**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(complete_dataset.columns)\n",
    "maths_cols=['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu','Mjob', 'Fjob', 'reason', 'nursery', 'internet', 'guardian.x','traveltime.x', 'studytime.x', 'failures.x', 'schoolsup.x', 'famsup.x','paid.x', 'activities.x', 'higher.x', 'romantic.x', 'famrel.x','freetime.x', 'goout.x', 'Dalc.x', 'Walc.x', 'health.x', 'absences.x','G3.x']\n",
    "port_cols=['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu','Mjob', 'Fjob', 'reason', 'nursery', 'internet', 'guardian.y','traveltime.y', 'studytime.y', 'failures.y', 'schoolsup.y', 'famsup.y','paid.y', 'activities.y', 'higher.y', 'romantic.y', 'famrel.y','freetime.y', 'goout.y', 'Dalc.y', 'Walc.y', 'health.y', 'absences.y','G3.y']\n",
    "maths_dataset=complete_dataset[maths_cols]\n",
    "port_dataset=complete_dataset[port_cols]\n",
    "maths_features=maths_dataset[maths_cols[:-1]]\n",
    "maths_labels=maths_dataset[maths_cols[-1]]\n",
    "port_features=port_dataset[port_cols[:-1]]\n",
    "port_labels=port_dataset[port_cols[-1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit random forest classifier on entire  dataset and predict probabilities for entire dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maths dataset...................\n",
      "[0.79, 0.12, 0.81, 0.28, 0.76, 0.66, 0.07, 0.13, 0.93, 0.83, 0.96, 0.22, 0.94, 0.91, 0.96, 0.96, 0.95, 0.16, 0.26, 0.06, 0.11, 0.9, 0.97, 0.94, 0.27, 0.74, 0.17, 0.08, 0.3, 0.9, 0.93, 0.94, 0.84, 0.22, 0.78, 0.31, 0.95, 0.85, 0.93, 0.76, 0.94, 0.84, 0.78, 0.11, 0.12, 0.96, 0.89, 0.74, 0.12, 0.8, 0.86, 0.67, 0.25, 0.28, 0.95, 0.91, 0.07, 0.82, 0.97, 0.83, 0.13, 0.93, 0.96, 0.3, 0.87, 0.77, 0.27, 0.9, 0.95, 0.93, 0.96, 0.07, 0.14, 0.93, 0.84, 1.0, 0.97, 0.95, 0.96, 0.96, 0.91, 0.29, 0.3, 0.09, 0.83, 0.98, 0.97, 0.13, 0.29, 0.98, 0.9, 0.94, 0.94, 0.82, 0.18, 0.33, 0.9, 0.91, 0.35, 0.93, 0.93, 0.95, 0.92, 0.12, 0.27, 0.89, 0.1, 0.2, 0.08, 0.12, 0.83, 0.87, 0.88, 0.9, 0.3, 0.27, 0.91, 0.94, 0.91, 0.91, 0.89, 0.41, 0.28, 0.15, 0.96, 0.9, 0.89, 0.99, 0.13, 0.72, 0.72, 0.15, 0.15, 0.89, 0.92, 0.94, 0.74, 0.33, 0.96, 0.96, 0.35, 0.92, 0.97, 0.19, 0.7, 0.15, 0.25, 0.05, 0.89, 0.88, 0.07, 0.91, 0.91, 0.23, 0.3, 0.91, 0.27, 0.88, 0.86, 0.92, 0.28, 0.28, 0.95, 0.88, 0.07, 0.95, 0.9, 0.84, 0.27, 0.93, 0.32, 0.06, 0.22, 0.06, 0.31, 0.29, 0.19, 0.22, 0.89, 0.9, 0.95, 0.96, 0.91, 0.95, 0.87, 0.96, 0.74, 0.85, 0.96, 0.98, 0.82, 0.96, 0.98, 0.99, 0.97, 0.94, 0.96, 0.96, 0.16, 0.96, 0.95, 0.95, 0.98, 0.99, 1.0, 0.92, 0.78, 0.97, 0.79, 0.96, 0.16, 0.94, 0.98, 0.98, 0.92, 0.97, 1.0, 0.94, 0.96, 0.39, 0.92, 0.94, 0.29, 0.78, 0.91, 0.93, 0.97, 0.88, 0.98, 0.94, 0.88, 0.77, 1.0, 0.92, 1.0, 0.95, 0.95, 0.74, 0.74, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11, 1.0, 0.32, 0.96, 0.97, 0.98, 0.98, 0.2, 1.0, 0.13, 0.13, 1.0, 1.0, 0.89, 0.81, 0.31, 0.41, 0.75, 0.85, 0.96, 0.98, 0.97, 0.08, 0.98, 0.97, 0.98, 0.32, 0.94, 0.9, 0.09, 0.93, 0.97, 0.88, 0.32, 0.94, 0.07, 0.96, 0.08, 0.95, 0.3, 0.01, 0.01, 0.94, 0.94, 1.0, 0.89, 0.1, 0.98, 0.25, 0.95, 0.97, 0.98, 0.98, 0.1, 0.75, 0.19, 0.11, 0.9, 0.97, 0.9, 0.3, 0.98, 0.92, 0.92, 0.88, 0.95, 0.97, 0.99, 0.04, 0.95, 0.07, 0.94, 0.96, 0.13, 0.08, 0.12, 0.93, 0.94, 0.32, 0.29, 0.97, 0.08, 0.08, 0.01, 0.01, 0.93, 0.08, 0.11, 0.35, 0.12, 0.98, 0.94, 0.91, 0.67, 0.09, 0.9, 0.89, 0.13, 0.1, 0.41, 0.94, 0.9, 0.94, 0.85, 0.89, 0.9, 0.9, 0.91, 0.95, 0.33, 0.95, 0.93, 0.06, 0.06, 0.91, 0.94, 0.21, 0.95, 0.92, 0.25, 0.06, 0.95, 0.98, 0.93, 0.95, 0.9, 0.27, 0.77, 0.16, 0.9, 0.94, 0.93, 0.92, 0.13, 0.94, 0.12, 0.1, 0.07, 0.07, 0.99, 0.97, 0.91, 0.95, 0.94, 0.91, 0.97, 0.96, 0.87, 0.9, 0.12, 0.9, 0.93, 0.92, 0.98, 0.13, 0.09, 0.93, 0.93, 0.86, 0.97, 0.9, 0.96, 0.9, 0.92, 0.95, 0.12, 0.93, 0.91, 0.95, 0.12, 0.93, 0.91, 0.91, 0.95, 0.92, 0.95, 0.96, 0.14, 0.91, 0.95, 0.93, 0.96, 0.95, 0.99, 0.23, 0.91, 0.94, 0.13, 0.11, 0.95, 0.89, 0.95, 0.91, 0.88, 0.98, 0.94, 0.06, 0.94, 0.89, 0.9, 0.09, 0.88, 0.88, 0.23, 0.94, 0.1, 0.95, 0.07, 0.95, 0.95, 0.96, 0.97, 0.99, 0.05, 0.97, 0.95, 0.97, 0.18, 0.88, 0.92, 0.07, 0.24, 0.92, 0.92, 0.07, 0.11, 0.97, 0.09, 0.92, 0.9, 0.11, 0.96, 0.98, 0.37, 0.94, 0.96, 0.95, 0.93, 0.94, 0.86, 0.15, 0.1, 0.1, 0.92, 0.96, 0.1, 0.92, 0.1, 0.97, 0.97, 0.94, 0.12, 0.9, 0.96, 0.94, 0.93, 0.93, 0.9, 0.96, 0.9, 0.15, 0.95, 0.15, 0.95, 0.85, 0.87, 0.94, 0.08, 0.98, 0.32, 0.93, 0.11, 0.96, 0.27, 0.88, 0.96, 0.18, 0.96, 0.95, 0.05, 0.1, 0.37, 0.95, 0.09, 0.12, 0.15, 0.9, 0.09, 0.96, 0.92, 0.12, 0.96, 0.91, 0.11, 0.94, 0.9, 0.91, 0.94, 0.09, 0.92, 0.97, 0.08, 0.88, 0.92, 0.96, 0.91, 0.97, 0.19, 0.94, 0.92, 0.95, 0.91, 0.16, 0.98, 0.97, 0.92, 0.12, 0.95, 0.89, 0.08, 0.11, 0.09, 0.96, 0.91, 0.92, 0.95, 0.94, 0.91, 0.09, 0.94, 0.04, 0.9, 0.96, 0.97, 0.14, 0.95, 0.25, 0.15, 0.93, 0.88, 0.08, 0.98, 0.92, 0.99, 0.97, 0.98, 0.98, 0.96, 0.91, 0.07, 0.96, 0.91, 0.97, 0.96, 0.93, 0.9, 0.08, 0.96, 0.93, 0.96, 0.32, 0.19, 0.92, 0.92, 0.94, 0.09, 0.89, 0.9, 0.07, 0.34, 0.98, 0.98, 0.08, 0.99, 0.24, 0.98, 0.95, 0.92, 0.89, 0.95, 0.91, 0.09, 0.07, 0.93, 0.09, 1.0, 0.83, 0.98, 0.97, 0.9, 0.89, 0.93, 0.27, 0.96, 0.14, 0.06, 0.95, 0.91, 0.09, 0.9, 0.95, 0.96, 0.93, 0.96, 0.92, 0.22, 0.89, 0.97, 0.99, 0.92, 0.16, 0.09, 0.92, 0.08, 0.86, 0.1, 0.1, 0.88, 0.03, 0.9, 0.05, 0.93, 0.27, 0.09, 0.9, 0.99, 0.95, 0.88, 0.93, 0.92, 0.98, 0.98, 0.07, 0.95, 0.9, 0.1, 0.94, 0.9, 0.91, 0.92, 0.06, 0.13, 0.07, 0.95, 0.96, 0.94, 0.15, 0.98, 0.97, 0.95, 0.11, 0.99, 0.97, 0.08, 0.16, 0.13, 0.99, 0.14, 0.08, 0.95, 0.96, 0.97, 0.98, 0.94, 0.95, 0.96, 0.95, 0.98, 0.91, 0.93, 0.2, 0.95, 0.95, 0.11, 0.92, 0.09, 0.93, 0.87, 0.92, 0.94, 0.95, 0.94, 0.09, 0.96, 0.93, 0.17, 0.11, 0.04, 0.96, 0.1, 0.89, 0.99, 0.93, 0.95, 0.96, 0.89, 0.95, 0.05, 0.04, 0.95, 0.95, 0.87, 0.04, 0.97, 0.94, 0.9, 0.17, 0.06, 0.94, 0.1, 0.08, 0.95, 0.9, 0.89, 0.94, 0.97, 0.96, 0.11, 0.97, 0.98, 0.94, 0.09, 0.91, 0.95, 0.94, 0.92, 0.94, 0.16, 0.92, 0.98, 0.96, 0.96, 0.88, 0.88, 0.11, 0.95, 0.94, 0.97, 0.94, 0.96, 0.13, 0.07, 0.89, 0.93, 0.93, 0.95, 0.91, 0.9, 0.17, 0.94, 0.93, 0.18, 0.93, 0.9, 0.24, 0.87, 0.09, 0.14, 0.06, 0.16, 0.98, 0.93, 0.96, 0.92, 0.04, 0.96, 0.99, 0.9, 0.93, 0.14, 0.89, 0.97, 0.9, 0.26, 0.94, 0.07, 0.91, 0.99, 0.1, 0.95, 0.98, 0.97, 0.94, 0.25, 0.17, 0.9, 0.91, 0.97, 0.94, 0.16, 0.87, 0.91, 0.95, 0.88, 0.99, 0.97, 0.89, 0.05, 0.97, 0.1, 0.98, 0.99, 0.12, 0.94, 0.03, 0.96, 0.93, 0.97, 0.09, 0.95, 0.89, 0.03, 0.94, 0.93, 0.09, 0.91, 0.96, 0.1, 0.96, 0.98, 0.11, 0.92, 0.07, 0.93, 0.99, 1.0, 0.96, 0.08, 0.94, 0.98, 0.94, 0.16, 0.9, 0.15, 0.98, 0.18, 0.97, 0.07]\n",
      "portuguese dataset.................\n",
      "[0.97, 0.94, 0.99, 0.99, 0.98, 0.99, 1.0, 0.94, 1.0, 0.98, 1.0, 0.97, 1.0, 0.98, 0.99, 1.0, 1.0, 0.98, 1.0, 0.98, 0.98, 1.0, 1.0, 0.99, 1.0, 0.96, 1.0, 0.97, 1.0, 1.0, 0.99, 0.98, 0.98, 0.99, 0.97, 1.0, 1.0, 0.98, 0.98, 1.0, 1.0, 0.99, 1.0, 1.0, 1.0, 1.0, 0.99, 0.76, 0.99, 0.99, 1.0, 0.99, 1.0, 0.99, 1.0, 0.99, 1.0, 1.0, 1.0, 0.99, 0.97, 0.99, 1.0, 1.0, 0.98, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97, 0.98, 1.0, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 1.0, 1.0, 0.97, 0.98, 0.97, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.99, 1.0, 1.0, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 0.29, 1.0, 1.0, 1.0, 1.0, 0.99, 0.98, 0.97, 0.99, 1.0, 0.99, 1.0, 0.99, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 1.0, 0.92, 0.9, 0.94, 0.99, 0.3, 0.99, 0.98, 0.97, 1.0, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 0.94, 1.0, 0.98, 1.0, 0.96, 0.38, 0.99, 1.0, 0.97, 1.0, 1.0, 0.96, 0.98, 0.96, 0.99, 0.39, 0.99, 0.99, 1.0, 0.25, 1.0, 0.99, 1.0, 1.0, 1.0, 1.0, 0.99, 0.99, 0.96, 0.94, 1.0, 0.99, 1.0, 1.0, 1.0, 0.96, 0.99, 0.35, 1.0, 0.97, 1.0, 0.98, 1.0, 0.97, 1.0, 0.99, 1.0, 0.99, 0.99, 1.0, 0.99, 1.0, 1.0, 0.96, 0.96, 0.95, 0.99, 0.99, 0.99, 0.79, 1.0, 1.0, 0.98, 1.0, 1.0, 0.99, 0.98, 0.3, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.32, 1.0, 1.0, 0.12, 1.0, 0.12, 0.94, 0.99, 0.97, 0.43, 0.91, 0.94, 0.99, 1.0, 0.99, 1.0, 1.0, 1.0, 0.99, 0.99, 0.98, 0.98, 0.98, 0.97, 1.0, 0.96, 0.98, 0.98, 0.25, 0.87, 0.28, 1.0, 0.95, 0.94, 0.16, 0.94, 0.16, 1.0, 0.99, 0.24, 1.0, 1.0, 0.97, 1.0, 1.0, 1.0, 1.0, 0.99, 0.93, 0.97, 0.96, 0.99, 0.99, 0.99, 1.0, 0.97, 1.0, 0.98, 0.98, 0.99, 0.98, 1.0, 0.98, 0.21, 1.0, 0.89, 0.23, 0.99, 0.28, 0.99, 1.0, 1.0, 0.99, 1.0, 1.0, 0.99, 1.0, 0.99, 1.0, 0.17, 0.98, 0.95, 1.0, 1.0, 1.0, 0.98, 0.97, 0.94, 1.0, 0.95, 0.14, 0.29, 0.37, 0.95, 0.29, 0.99, 0.97, 0.99, 0.96, 0.94, 0.94, 0.26, 0.95, 0.94, 0.98, 0.27, 0.36, 1.0, 0.97, 0.99, 0.99, 0.99, 0.96, 0.96, 0.92, 0.99, 1.0, 0.96, 0.33, 0.33, 0.88, 0.32, 0.87, 0.94, 0.99, 0.95, 0.35, 1.0, 0.9, 0.87, 0.25, 1.0, 1.0, 0.99, 1.0, 0.96, 0.99, 0.99, 0.98, 1.0, 1.0, 1.0, 0.99, 0.95, 1.0, 0.97, 0.94, 0.99, 0.99, 0.98, 1.0, 0.98, 1.0, 0.99, 1.0, 0.98, 1.0, 0.98, 0.95, 0.99, 0.99, 1.0, 0.99, 0.99, 0.96, 0.93, 0.96, 1.0, 0.93, 1.0, 1.0, 1.0, 0.99, 0.98, 0.94, 0.98, 0.15, 1.0, 0.99, 1.0, 1.0, 0.98, 0.99, 0.95, 0.99, 0.99, 0.99, 1.0, 1.0, 0.93, 1.0, 0.89, 0.98, 0.96, 1.0, 1.0, 0.93, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97, 0.95, 0.98, 0.24, 1.0, 0.99, 1.0, 0.99, 0.96, 0.95, 0.99, 0.98, 0.99, 0.99, 0.99, 1.0, 0.97, 1.0, 1.0, 1.0, 0.98, 0.26, 0.91, 0.98, 1.0, 0.99, 0.99, 1.0, 0.97, 0.99, 0.99, 0.23, 0.99, 0.98, 1.0, 1.0, 1.0, 0.98, 1.0, 0.99, 1.0, 0.99, 1.0, 1.0, 0.99, 0.98, 0.97, 1.0, 0.92, 0.99, 0.99, 0.96, 1.0, 0.99, 0.98, 1.0, 0.96, 0.98, 0.98, 1.0, 1.0, 1.0, 0.99, 0.93, 0.97, 1.0, 1.0, 1.0, 0.99, 0.99, 0.99, 1.0, 1.0, 0.99, 1.0, 0.98, 0.97, 1.0, 0.96, 0.99, 0.99, 0.96, 0.99, 1.0, 0.97, 1.0, 0.93, 1.0, 1.0, 1.0, 0.97, 0.99, 1.0, 0.97, 0.92, 0.99, 0.96, 0.98, 0.99, 0.98, 1.0, 0.98, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.97, 0.95, 0.98, 0.99, 0.98, 1.0, 0.99, 0.99, 1.0, 0.97, 0.98, 0.97, 0.99, 0.99, 0.95, 1.0, 0.99, 1.0, 0.97, 1.0, 1.0, 1.0, 0.99, 0.99, 0.98, 0.98, 0.9, 1.0, 1.0, 1.0, 1.0, 0.3, 1.0, 1.0, 0.95, 0.99, 0.98, 1.0, 0.3, 1.0, 0.99, 1.0, 0.99, 0.96, 1.0, 1.0, 0.99, 0.96, 0.98, 0.96, 1.0, 1.0, 0.96, 0.97, 1.0, 1.0, 0.98, 0.99, 0.99, 1.0, 0.98, 1.0, 0.98, 0.35, 0.31, 1.0, 0.87, 1.0, 1.0, 0.38, 1.0, 1.0, 0.99, 0.94, 1.0, 1.0, 0.98, 1.0, 1.0, 1.0, 0.98, 0.99, 1.0, 0.93, 0.98, 0.98, 0.94, 0.98, 1.0, 1.0, 0.92, 1.0, 0.99, 0.99, 1.0, 0.96, 0.99, 0.98, 0.98, 1.0, 0.97, 0.96, 0.98, 1.0, 0.99, 1.0, 0.96, 0.99, 0.25, 0.96, 1.0, 0.99, 0.91, 1.0, 1.0, 0.98, 0.99, 1.0, 1.0, 1.0, 0.99, 1.0, 1.0, 0.99, 0.97, 0.95, 0.99, 0.98, 1.0, 1.0, 0.99, 0.99, 0.93, 1.0, 0.97, 0.97, 1.0, 1.0, 0.98, 1.0, 0.99, 1.0, 0.97, 1.0, 0.97, 0.95, 0.98, 0.99, 0.97, 1.0, 0.98, 0.97, 0.99, 1.0, 0.96, 1.0, 1.0, 1.0, 0.89, 0.99, 0.98, 0.98, 0.99, 0.99, 0.95, 0.92, 0.98, 0.99, 1.0, 0.99, 0.95, 1.0, 1.0, 0.99, 0.98, 1.0, 0.98, 0.98, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.93, 0.91, 0.96, 1.0, 1.0, 1.0, 0.99, 1.0, 0.42, 1.0, 0.99, 0.99, 0.97, 0.98, 1.0, 0.97, 1.0, 0.98, 1.0, 0.99, 0.95, 0.97, 0.96, 1.0, 1.0, 0.98, 0.96, 0.99, 0.99, 0.99, 0.99, 1.0, 1.0, 0.99, 0.97, 0.99, 0.94, 0.99, 0.99, 1.0, 1.0, 0.99, 0.99, 0.91, 0.99, 0.99, 1.0, 0.95, 0.95, 0.33, 1.0, 0.99, 1.0, 0.98, 1.0, 0.96, 0.98, 0.93, 0.98, 0.93, 1.0, 1.0, 1.0, 0.99, 1.0, 0.99, 1.0, 0.99, 0.98, 0.99, 1.0, 1.0, 0.96, 0.9, 1.0, 0.96, 0.97, 0.99, 0.93, 0.99, 1.0, 1.0, 0.99, 0.99, 0.98, 1.0, 0.99, 1.0, 0.99, 0.98, 1.0, 1.0, 1.0, 0.98, 1.0, 0.99, 0.93, 1.0, 1.0, 0.98, 1.0, 1.0, 1.0, 1.0, 0.99, 0.35, 0.96, 0.97, 0.92, 0.99, 0.98, 0.97, 0.99, 1.0, 1.0, 1.0, 0.95, 0.98, 1.0, 1.0, 0.99, 1.0, 0.97, 0.95, 0.98, 0.99, 1.0, 0.99, 0.99, 0.98, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "def predict_train_probabilities(model,features,labels):\n",
    "    model.fit(features,labels)#fit entire dataset\n",
    "    preds=model.predict_proba(features)#predict probabilities for entire dataset\n",
    "    initial_probs=[]\n",
    "    for i in preds:\n",
    "        initial_probs.append(i[1])#probability for passing in G3 exam \n",
    "    return initial_probs\n",
    "rand_forest=RandomForestClassifier(random_state=0)#random forest \n",
    "initial_maths=predict_train_probabilities(rand_forest,maths_features,maths_labels)\n",
    "initial_pors=predict_train_probabilities(rand_forest,port_features,port_labels)\n",
    "maths_dataset['g3_pass']=initial_maths#create a column for g3 pass probabilities in the maths dataset\n",
    "port_dataset['g3_pass']=initial_pors#create a column for g3 pass probabilities in the portuguese dataset\n",
    "print('maths dataset...................')\n",
    "print(initial_maths)\n",
    "print('portuguese dataset.................')\n",
    "print(initial_pors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select a student randomly who has failed in the G3 exam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 30)\n",
      "(1, 30)\n",
      "the initial probability for the selected student to pass in g3 of maths subject is 765    0.09\n",
      "Name: g3_pass, dtype: float64\n",
      "     studytime.x  failures.x  schoolsup.x  paid.x  activities.x  freetime.x  \\\n",
      "765            2           3            0       0             1           2   \n",
      "\n",
      "     health.x  absences.x  \n",
      "765         5           3  \n",
      "*************************************************************\n",
      "the initial probability for the selected student to pass in g3 of portuguese subject is 345    0.29\n",
      "Name: g3_pass, dtype: float64\n",
      "     studytime.y  failures.y  schoolsup.y  paid.y  activities.y  freetime.y  \\\n",
      "345            2           0            0       0             1           5   \n",
      "\n",
      "     health.y  absences.y  \n",
      "345         1           3  \n"
     ]
    }
   ],
   "source": [
    "def choose_student(features,prcol,dataset,marks):\n",
    "    failed_students_info=dataset[dataset[marks]==0]# all students who have failed in G1\n",
    "    selected_student=failed_students_info.sample(n=1)#selecting one student randomly\n",
    "    initial_probab=selected_student[prcol]#initial probability for the student\n",
    "    sample_student=selected_student[features]#only features \n",
    "    print(sample_student.shape)\n",
    "    return initial_probab,sample_student\n",
    "maths_feature_cols=maths_cols[:-1]# maths feature columns\n",
    "por_feature_cols=port_cols[:-1]#portuguese feature columns\n",
    "maths_initial_probability,maths_sample_student=choose_student(maths_feature_cols,'g3_pass',maths_dataset,'G3.x')\n",
    "por_initial_probability,por_sample_student=choose_student(por_feature_cols,'g3_pass',port_dataset,'G3.y')\n",
    "#maths_explore_cols and por_explore_cols are the columns which would be explored in scenarios\n",
    "maths_explore_cols=['studytime.x','failures.x','schoolsup.x','paid.x','activities.x','freetime.x','health.x','absences.x']\n",
    "por_explore_cols=['studytime.y','failures.y','schoolsup.y','paid.y','activities.y','freetime.y','health.y','absences.y']\n",
    "print('the initial probability for the selected student to pass in g3 of maths subject is %r' % maths_initial_probability)\n",
    "print(maths_sample_student[maths_explore_cols])\n",
    "print('*************************************************************')\n",
    "print('the initial probability for the selected student to pass in g3 of portuguese subject is %r' % por_initial_probability)\n",
    "print(por_sample_student[por_explore_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**calculate_category_probabs calculates the change in probabilities for each category of a feature i.e . If the student has a studytime of category 1 ,initial pass probability of 0.2. Then the following function would return the change in probabilities if the studytime is 2 or 3 or 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "studytime.x\n",
      " the current value for the student in this 'studytime.x' is 2 \n",
      "The other unique values of this 'studytime.x' are [4, 1, 3] \n",
      "{4: 0.0, 1: -0.05, 3: 0.0}\n",
      "failures.x\n",
      " the current value for the student in this 'failures.x' is 3 \n",
      "The other unique values of this 'failures.x' are [1, 2, 0] \n",
      "{1: 0.07, 2: 0.04, 0: 0.13}\n",
      "schoolsup.x\n",
      " the current value for the student in this 'schoolsup.x' is 0 \n",
      "The other unique values of this 'schoolsup.x' are [1] \n",
      "{1: -0.03}\n",
      "paid.x\n",
      " the current value for the student in this 'paid.x' is 0 \n",
      "The other unique values of this 'paid.x' are [1] \n",
      "{1: -0.07}\n",
      "activities.x\n",
      " the current value for the student in this 'activities.x' is 1 \n",
      "The other unique values of this 'activities.x' are [0] \n",
      "{0: 0.0}\n",
      "freetime.x\n",
      " the current value for the student in this 'freetime.x' is 2 \n",
      "The other unique values of this 'freetime.x' are [1, 3, 4, 5] \n",
      "{1: 0.0, 3: 0.0, 4: -0.02, 5: -0.02}\n",
      "health.x\n",
      " the current value for the student in this 'health.x' is 5 \n",
      "The other unique values of this 'health.x' are [1, 2, 3, 4] \n",
      "{1: -0.02, 2: 0.0, 3: 0.0, 4: 0.0}\n",
      "absences.x\n",
      " the current value for the student in this 'absences.x' is 3 \n",
      "The other unique values of this 'absences.x' are [1, 2, 4, 5] \n",
      "{1: -0.01, 2: -0.02, 4: -0.04, 5: -0.04}\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "next.........................................................................\n",
      "studytime.y\n",
      " the current value for the student in this 'studytime.y' is 2 \n",
      "The other unique values of this 'studytime.y' are [4, 1, 3] \n",
      "{4: 0.03, 1: 0.08, 3: 0.03}\n",
      "failures.y\n",
      " the current value for the student in this 'failures.y' is 0 \n",
      "The other unique values of this 'failures.y' are [1, 3, 2] \n",
      "{1: 0.03, 3: 0.11, 2: 0.07}\n",
      "schoolsup.y\n",
      " the current value for the student in this 'schoolsup.y' is 0 \n",
      "The other unique values of this 'schoolsup.y' are [1] \n",
      "{1: 0.05}\n",
      "paid.y\n",
      " the current value for the student in this 'paid.y' is 0 \n",
      "The other unique values of this 'paid.y' are [1] \n",
      "{1: 0.03}\n",
      "activities.y\n",
      " the current value for the student in this 'activities.y' is 1 \n",
      "The other unique values of this 'activities.y' are [0] \n",
      "{0: 0.11}\n",
      "freetime.y\n",
      " the current value for the student in this 'freetime.y' is 5 \n",
      "The other unique values of this 'freetime.y' are [1, 3, 2, 4] \n",
      "{1: 0.22, 3: 0.2, 2: 0.21, 4: 0.12}\n",
      "health.y\n",
      " the current value for the student in this 'health.y' is 1 \n",
      "The other unique values of this 'health.y' are [5, 2, 3, 4] \n",
      "{5: 0.25, 2: 0.16, 3: 0.2, 4: 0.23}\n",
      "absences.y\n",
      " the current value for the student in this 'absences.y' is 3 \n",
      "The other unique values of this 'absences.y' are [2, 1, 4] \n",
      "{2: 0.22, 1: 0.24, 4: 0.02}\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "next.........................................................................\n"
     ]
    }
   ],
   "source": [
    "def calculate_category_probabs(feature,student,dataset):\n",
    "    present_value=int(student[feature])#present value of the student for this feature\n",
    "    print(' the current value for the student in this %r is %r ' % (feature,present_value))\n",
    "    possible_values=dataset[feature].unique().tolist()#finding all values that this feature can have i.e schoolsup.x can have 0 or 1\n",
    "    interested_values=[]#stores all values which are to be explored for scenarios\n",
    "    for val in possible_values:\n",
    "        if val!=present_value:#if the value is not the present value\n",
    "            interested_values.append(val)\n",
    "    print('The other unique values of this %r are %r ' % (feature,interested_values))\n",
    "    scenarios={}#key-> category value like 1 or 2 or 3 ,value-> change in probability when compared to the probability of present value\n",
    "    \n",
    "    for v in interested_values:\n",
    "        #student.loc[:,feature]=v\n",
    "        test_case=student.copy(deep=True)#creating a copy of the current student \n",
    "        test_case.loc[:,feature]=v#changing the feature value in the copied dataframe\n",
    "        #print(test_case)\n",
    "        df=student.append(test_case)#combine the current student info and new scenario info \n",
    "        p=rand_forest.predict_proba(df)#predict probabilities for two rows\n",
    "        #print(df)\n",
    "        pl=list(p)\n",
    "        ap=[]# will contain the probability of passing in G1 for current situation and a new scenario\n",
    "        for l in pl:\n",
    "            ap.append(l[1])\n",
    "        diff=ap[1]-ap[0]#the difference in the probability of passing in G1 for a new scenario and current situation \n",
    "        \"\"\"The diff will tell us about the chanage in probability if a feature value changes i.e. let us consider a student who have \n",
    "        failures as 0 and G3 pass probability as 0.4 .we are exploring a scenario where the student will have failures as 1 then G3\n",
    "        pass probability would be 0.25 .The diff would -0.15 which means probability  decreases by 0.15\"\"\"\n",
    "        if v not in scenarios.keys():\n",
    "            scenarios[v]=round(diff,3)\n",
    "    print(scenarios)\n",
    "    #return scenarios\n",
    "exp=[maths_explore_cols,por_explore_cols] \n",
    "students=[maths_sample_student,por_sample_student]\n",
    "datasets=[maths_dataset,port_dataset]\n",
    "for i in range(2):\n",
    "    for col in exp[i]:\n",
    "        print(col)\n",
    "        calculate_category_probabs(col,students[i],datasets[i])\n",
    "    print('$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$')\n",
    "    print('next.........................................................................')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore scenarios for combination of two features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_combinations(first_feature,second_feature):\n",
    "    combinations=[]\n",
    "    for i in first_feature:\n",
    "        for j in second_feature:\n",
    "            combinations.append((i,j))\n",
    "    return combinations\n",
    "def two_features_combination(feature1,feature2,student,dataset):\n",
    "    combination_scenarios={}\n",
    "    feature1_uniques=dataset[feature1].unique().tolist()#unique values for first feature\n",
    "    feature2_uniques=dataset[feature2].unique().tolist()#unique values for second feature\n",
    "    feature1_pv=int(student[feature1])#present value for feature 1\n",
    "    feature2_pv=int(student[feature2])#present value for feature 2\n",
    "    given_combo=(feature1_pv,feature2_pv)\n",
    "    all_combinations=build_combinations(feature1_uniques,feature2_uniques)#get combinations of both features\n",
    "    interesting_combinations=[]#contains all combinations other than given combination\n",
    "    for i in all_combinations:\n",
    "        if i!=given_combo and i[0]!=given_combo[0] and i[1]!=given_combo[1]:#change in both categories\n",
    "            interesting_combinations.append(i)\n",
    "    for i in interesting_combinations:#similar logic to that explained for single feature\n",
    "        test_scenario=student.copy(deep=True)\n",
    "        test_scenario.loc[:,feature1]=i[0]\n",
    "        test_scenario.loc[:,feature2]=i[1]\n",
    "        df=student.append(test_scenario)\n",
    "        probabs=rand_forest.predict_proba(df)\n",
    "        compare=[]\n",
    "        for j in probabs:\n",
    "            compare.append(j[1])\n",
    "        diff=compare[1]-compare[0]\n",
    "        if i not in combination_scenarios.keys():\n",
    "            combination_scenarios[i]=round(diff,3)\n",
    "    return combination_scenarios\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('studytime.y', 'paid.y')\n",
      "{(4, 1): 0.04, (1, 1): 0.09, (3, 1): 0.04}\n",
      "('studytime.y', 'schoolsup.y')\n",
      "{(4, 1): 0.06, (1, 1): 0.11, (3, 1): 0.06}\n",
      "('studytime.y', 'failures.y')\n",
      "{(4, 1): 0.05, (4, 3): 0.14, (4, 2): 0.1, (1, 1): 0.06, (1, 3): 0.12, (1, 2): 0.1, (3, 1): 0.05, (3, 3): 0.14, (3, 2): 0.1}\n",
      "('failures.y', 'paid.y')\n",
      "{(1, 1): 0.05, (3, 1): 0.1, (2, 1): 0.08}\n",
      "('studytime.y', 'freetime.y')\n",
      "{(4, 1): 0.25, (4, 3): 0.22, (4, 2): 0.23, (4, 4): 0.15, (1, 1): 0.27, (1, 3): 0.25, (1, 2): 0.26, (1, 4): 0.18, (3, 1): 0.25, (3, 3): 0.22, (3, 2): 0.23, (3, 4): 0.15}\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "next.........................................................................\n",
      "('studytime.y', 'paid.y')\n",
      "{(4, 1): 0.04, (1, 1): 0.09, (3, 1): 0.04}\n",
      "('studytime.y', 'schoolsup.y')\n",
      "{(4, 1): 0.06, (1, 1): 0.11, (3, 1): 0.06}\n",
      "('studytime.y', 'failures.y')\n",
      "{(4, 1): 0.05, (4, 3): 0.14, (4, 2): 0.1, (1, 1): 0.06, (1, 3): 0.12, (1, 2): 0.1, (3, 1): 0.05, (3, 3): 0.14, (3, 2): 0.1}\n",
      "('failures.y', 'paid.y')\n",
      "{(1, 1): 0.05, (3, 1): 0.1, (2, 1): 0.08}\n",
      "('studytime.y', 'freetime.y')\n",
      "{(4, 1): 0.25, (4, 3): 0.22, (4, 2): 0.23, (4, 4): 0.15, (1, 1): 0.27, (1, 3): 0.25, (1, 2): 0.26, (1, 4): 0.18, (3, 1): 0.25, (3, 3): 0.22, (3, 2): 0.23, (3, 4): 0.15}\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "next.........................................................................\n"
     ]
    }
   ],
   "source": [
    "maths_combo_features=[('studytime.x','paid.x'),('studytime.x','schoolsup.x'),('studytime.x','failures.x'),('failures.x','paid.x'),('studytime.x','freetime.x')]\n",
    "por_combo_features=[('studytime.y','paid.y'),('studytime.y','schoolsup.y'),('studytime.y','failures.y'),('failures.y','paid.y'),('studytime.y','freetime.y')]\n",
    "total_combo_features=[maths_combo_features,por_combo_features]\n",
    "for a in range(2):\n",
    "    for col in total_combo_features[i]:\n",
    "        print(col)\n",
    "        print(two_features_combination(col[0],col[1],students[i],datasets[i]))\n",
    "    print('$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$')\n",
    "    print('next.........................................................................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
