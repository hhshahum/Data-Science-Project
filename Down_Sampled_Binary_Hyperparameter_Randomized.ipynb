{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import rankdata\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_combined_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel.y</th>\n",
       "      <th>freetime.y</th>\n",
       "      <th>goout.y</th>\n",
       "      <th>Dalc.y</th>\n",
       "      <th>Walc.y</th>\n",
       "      <th>health.y</th>\n",
       "      <th>absences.y</th>\n",
       "      <th>G1.y</th>\n",
       "      <th>G2.y</th>\n",
       "      <th>G3.y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   school  sex  age  address  famsize  Pstatus  Medu  Fedu  Mjob  Fjob  ...  \\\n",
       "0       0    0   15        0        0        1     1     1     0     2  ...   \n",
       "1       0    0   15        0        0        1     1     1     2     2  ...   \n",
       "2       0    0   15        0        0        1     2     2     0     2  ...   \n",
       "3       0    0   15        0        0        1     2     4     3     1  ...   \n",
       "4       0    0   15        0        0        1     3     3     3     3  ...   \n",
       "\n",
       "   famrel.y  freetime.y  goout.y  Dalc.y  Walc.y  health.y  absences.y  G1.y  \\\n",
       "0         3           1        2       1       1         1           4    13   \n",
       "1         3           3        4       2       4         5           2    13   \n",
       "2         4           3        1       1       1         2           8    14   \n",
       "3         4           3        2       1       1         5           2    10   \n",
       "4         4           2        1       2       3         3           2    13   \n",
       "\n",
       "   G2.y  G3.y  \n",
       "0    13    13  \n",
       "1    11    11  \n",
       "2    13    12  \n",
       "3    11    10  \n",
       "4    13    13  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {'Unnamed: 0':'ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
       "       'Mjob', 'Fjob', 'reason', 'nursery', 'internet', 'guardian.x',\n",
       "       'traveltime.x', 'studytime.x', 'failures.x', 'schoolsup.x', 'famsup.x',\n",
       "       'paid.x', 'activities.x', 'higher.x', 'romantic.x', 'famrel.x',\n",
       "       'freetime.x', 'goout.x', 'Dalc.x', 'Walc.x', 'health.x', 'absences.x',\n",
       "       'G1.x', 'G2.x', 'G3.x', 'guardian.y', 'traveltime.y', 'studytime.y',\n",
       "       'failures.y', 'schoolsup.y', 'famsup.y', 'paid.y', 'activities.y',\n",
       "       'higher.y', 'romantic.y', 'famrel.y', 'freetime.y', 'goout.y', 'Dalc.y',\n",
       "       'Walc.y', 'health.y', 'absences.y', 'G1.y', 'G2.y', 'G3.y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfeatures=['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
    "       'Mjob', 'Fjob', 'reason', 'nursery', 'internet', 'guardian.x',\n",
    "       'traveltime.x', 'studytime.x', 'failures.x', 'schoolsup.x', 'famsup.x',\n",
    "       'paid.x', 'activities.x', 'higher.x', 'romantic.x', 'famrel.x',\n",
    "       'freetime.x', 'goout.x', 'Dalc.x', 'Walc.x', 'health.x', 'absences.x','G1.x','G3.x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "yfeatures = ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
    "       'Mjob', 'Fjob', 'reason', 'nursery', 'internet','guardian.y', 'traveltime.y', 'studytime.y',\n",
    "       'failures.y', 'schoolsup.y', 'famsup.y', 'paid.y', 'activities.y',\n",
    "       'higher.y', 'romantic.y', 'famrel.y', 'freetime.y', 'goout.y', 'Dalc.y',\n",
    "       'Walc.y', 'health.y', 'absences.y','G1.y','G3.y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keepcol = ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu',\n",
    "       'Fedu', 'Mjob', 'Fjob', 'reason', 'nursery', 'internet', 'guardian.x',\n",
    "       'traveltime.x', 'studytime.x', 'failures.x', 'schoolsup.x', 'famsup.x',\n",
    "       'paid.x', 'activities.x', 'higher.x', 'romantic.x', 'famrel.x',\n",
    "       'freetime.x', 'goout.x', 'Dalc.x', 'Walc.x', 'health.x', 'absences.x',\n",
    "       'G1.x', 'G2.x', 'G3.x', 'guardian.y', 'traveltime.y', 'studytime.y',\n",
    "       'failures.y', 'schoolsup.y', 'famsup.y', 'paid.y', 'activities.y',\n",
    "       'higher.y', 'romantic.y', 'famrel.y', 'freetime.y', 'goout.y', 'Dalc.y',\n",
    "       'Walc.y', 'health.y', 'absences.y', 'G1.y', 'G2.y', 'G3.y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fildf = df.loc[:,keepcol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fildf_x = fildf.loc[:,xfeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fildf_y = fildf.loc[:,yfeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(882, 32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fildf_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(882, 32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fildf_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertmarks(mark):\n",
    "    if mark<10:\n",
    "        return 'B'\n",
    "    else:\n",
    "        return 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlist=[]\n",
    "for i in fildf_x['G1.x']:\n",
    "    x = convertmarks(i)\n",
    "    newlist.append(x)\n",
    "fildf_x['New G1'] = newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlist=[]\n",
    "for i in fildf_y['G1.y']:\n",
    "    x = convertmarks(i)\n",
    "    newlist.append(x)\n",
    "fildf_y['New G1'] = newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlist=[]\n",
    "for i in fildf_x['G3.x']:\n",
    "    x = convertmarks(i)\n",
    "    newlist.append(x)\n",
    "fildf_x['New G3'] = newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlist=[]\n",
    "for i in fildf_y['G3.y']:\n",
    "    x = convertmarks(i)\n",
    "    newlist.append(x)\n",
    "fildf_y['New G3'] = newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      A\n",
       "1      A\n",
       "2      A\n",
       "3      A\n",
       "4      A\n",
       "      ..\n",
       "877    A\n",
       "878    A\n",
       "879    A\n",
       "880    A\n",
       "881    A\n",
       "Name: New G3, Length: 882, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fildf_y['New G3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fildf_x['New G1']= label_encoder.fit_transform(fildf_x['New G1'])\n",
    "fildf_y['New G1']= label_encoder.fit_transform(fildf_y['New G1'])\n",
    "fildf_x['New G3']= label_encoder.fit_transform(fildf_x['New G3'])\n",
    "fildf_y['New G3']= label_encoder.fit_transform(fildf_y['New G3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "877    0\n",
       "878    0\n",
       "879    0\n",
       "880    0\n",
       "881    0\n",
       "Name: New G3, Length: 882, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fildf_y['New G3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fildf_x = fildf_x.sample(frac=1,random_state=123)\n",
    "fildf_y = fildf_y.sample(frac=1,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    665\n",
       "1    217\n",
       "Name: New G1, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fildf_x['New G1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    606\n",
       "1    276\n",
       "Name: New G3, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fildf_x['New G3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = fildf_x['New G1'].value_counts().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [fildf_x]\n",
    "lst1=[]\n",
    "for class_index, group in fildf_x.groupby('New G1'):\n",
    "    lst1.append(group.sample(max_size, replace=True))\n",
    "fildf_x_G1 = pd.concat(lst1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    217\n",
       "0    217\n",
       "Name: New G1, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fildf_x_G1['New G1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = fildf_y['New G1'].value_counts().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    }
   ],
   "source": [
    "print(max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [fildf_y]\n",
    "lst1=[]\n",
    "for class_index, group in fildf_y.groupby('New G1'):\n",
    "    lst1.append(group.sample(max_size, replace=True))\n",
    "fildf_y_G1 = pd.concat(lst1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    69\n",
       "0    69\n",
       "Name: New G1, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fildf_y_G1['New G1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = fildf_x['New G3'].value_counts().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [fildf_x]\n",
    "lst1=[]\n",
    "for class_index, group in fildf_x.groupby('New G3'):\n",
    "    lst1.append(group.sample(max_size, replace=True))\n",
    "fildf_x_G3 = pd.concat(lst1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    276\n",
       "0    276\n",
       "Name: New G3, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fildf_x_G3['New G3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = fildf_y['New G3'].value_counts().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [fildf_y]\n",
    "lst1=[]\n",
    "for class_index, group in fildf_y.groupby('New G3'):\n",
    "    lst1.append(group.sample(max_size, replace=True))\n",
    "fildf_y_G3 = pd.concat(lst1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    46\n",
       "0    46\n",
       "Name: New G3, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fildf_y_G3['New G3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
       "       'Mjob', 'Fjob', 'reason', 'nursery', 'internet', 'guardian.y',\n",
       "       'traveltime.y', 'studytime.y', 'failures.y', 'schoolsup.y', 'famsup.y',\n",
       "       'paid.y', 'activities.y', 'higher.y', 'romantic.y', 'famrel.y',\n",
       "       'freetime.y', 'goout.y', 'Dalc.y', 'Walc.y', 'health.y', 'absences.y',\n",
       "       'G1.y', 'G3.y', 'New G1', 'New G3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fildf_y_G3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "fildf_x_G1 = fildf_x_G1.drop(['G1.x','G3.x'],axis=1)\n",
    "fildf_y_G1 = fildf_y_G1.drop(['G1.y','G3.y'],axis=1)\n",
    "fildf_x_G3 = fildf_x_G3.drop(['G1.x','G3.x'],axis=1)\n",
    "fildf_y_G3 = fildf_y_G3.drop(['G1.y','G3.y'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_x_G3 = fildf_x_G3.drop(['New G1','New G3'],axis=1)\n",
    "features_x_G1 = fildf_x_G1.drop(['New G1','New G3'],axis=1)\n",
    "features_y_G3 = fildf_y_G3.drop(['New G1','New G3'],axis=1)\n",
    "features_y_G1 = fildf_y_G1.drop(['New G1','New G3'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_x_G3 = fildf_x_G3['New G3']\n",
    "target_x_G1 = fildf_x_G1['New G1']\n",
    "target_y_G3 = fildf_y_G3['New G3']\n",
    "target_y_G1 = fildf_y_G1['New G1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_x_G1, X_test_x_G1, y_train_x_G1, y_test_x_G1 = train_test_split(features_x_G1, target_x_G1, test_size=0.25, random_state=0)\n",
    "X_train_y_G1, X_test_y_G1, y_train_y_G1, y_test_y_G1 = train_test_split(features_y_G1, target_y_G1, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_x_G3, X_test_x_G3, y_train_x_G3, y_test_x_G3 = train_test_split(features_x_G3, target_x_G3, test_size=0.25, random_state=0)\n",
    "X_train_y_G3, X_test_y_G3, y_train_y_G3, y_test_y_G3 = train_test_split(features_y_G3, target_y_G3, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_svc = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['linear','rbf', 'poly', 'sigmoid']}\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 10 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84        54\n",
      "           1       0.86      0.80      0.83        55\n",
      "\n",
      "    accuracy                           0.83       109\n",
      "   macro avg       0.84      0.84      0.83       109\n",
      "weighted avg       0.84      0.83      0.83       109\n",
      "\n",
      "[[47 11]\n",
      " [ 7 44]]\n",
      "Kappa Score: 0.6699192462987886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   18.0s finished\n"
     ]
    }
   ],
   "source": [
    "#grid_svc_x_G1 = GridSearchCV(SVC(),param_grid = param_grid_svc,refit=True,verbose=2,n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_svc_x_G1 = RandomizedSearchCV(SVC(),param_distributions = param_grid_svc,refit=True,verbose=2,n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_svc_x_G1.fit(X_train_x_G1,y_train_x_G1)\n",
    "print(grid_svc_x_G1.best_estimator_)\n",
    "y_pred_x_G1= grid_svc_x_G1.predict(X_test_x_G1)\n",
    "print(classification_report(y_pred_x_G1,y_test_x_G1,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_x_G1,y_pred_x_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G1,y_test_x_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 10 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 106 tasks      | elapsed:    0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.78        67\n",
      "           1       0.78      0.85      0.81        71\n",
      "\n",
      "    accuracy                           0.80       138\n",
      "   macro avg       0.80      0.80      0.80       138\n",
      "weighted avg       0.80      0.80      0.80       138\n",
      "\n",
      "[[50 11]\n",
      " [17 60]]\n",
      "Kappa Score: 0.5928345626975764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   27.4s finished\n"
     ]
    }
   ],
   "source": [
    "grid_svc_x_G3 = RandomizedSearchCV(SVC(),param_distributions = param_grid_svc,refit=True,verbose=2,n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_svc_x_G3.fit(X_train_x_G3,y_train_x_G3)\n",
    "print(grid_svc_x_G3.best_estimator_)\n",
    "y_pred_x_G3= grid_svc_x_G3.predict(X_test_x_G3)\n",
    "print(classification_report(y_pred_x_G3,y_test_x_G3,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_x_G3,y_pred_x_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G3,y_test_x_G3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 10 candidates, totalling 300 fits\n",
      "SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        20\n",
      "           1       0.86      0.80      0.83        15\n",
      "\n",
      "    accuracy                           0.86        35\n",
      "   macro avg       0.86      0.85      0.85        35\n",
      "weighted avg       0.86      0.86      0.86        35\n",
      "\n",
      "[[18  3]\n",
      " [ 2 12]]\n",
      "Kappa Score: 0.7058823529411764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "grid_svc_y_G1 = RandomizedSearchCV(SVC(),param_distributions = param_grid_svc,refit=True,verbose=2,n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_svc_y_G1.fit(X_train_y_G1,y_train_y_G1)\n",
    "print(grid_svc_y_G1.best_estimator_)\n",
    "y_pred_y_G1= grid_svc_y_G1.predict(X_test_y_G1)\n",
    "print(classification_report(y_pred_y_G1,y_test_y_G1,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_y_G1,y_pred_y_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G1,y_test_y_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 10 candidates, totalling 300 fits\n",
      "SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.87        16\n",
      "           1       0.67      0.86      0.75         7\n",
      "\n",
      "    accuracy                           0.83        23\n",
      "   macro avg       0.80      0.83      0.81        23\n",
      "weighted avg       0.85      0.83      0.83        23\n",
      "\n",
      "[[13  1]\n",
      " [ 3  6]]\n",
      "Kappa Score: 0.6198347107438017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "grid_svc_y_G3 = RandomizedSearchCV(SVC(),param_distributions = param_grid_svc,refit=True,verbose=2,n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_svc_y_G3.fit(X_train_y_G3,y_train_y_G3)\n",
    "print(grid_svc_y_G3.best_estimator_)\n",
    "y_pred_y_G3= grid_svc_y_G3.predict(X_test_y_G3)\n",
    "print(metrics.classification_report(y_pred_y_G3,y_test_y_G3,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_y_G3,y_pred_y_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G3,y_test_y_G3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "parameters_gbc = {\n",
    "    \"n_estimators\":[5,50,250,500],\n",
    "    \"max_depth\":[1,3,5,7,9],\n",
    "    \"learning_rate\":[0.01,0.1,1,10,100]\n",
    "}\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 10 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 285 out of 300 | elapsed:   22.6s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   23.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.01, loss='deviance', max_depth=7,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        58\n",
      "           1       0.92      0.92      0.92        51\n",
      "\n",
      "    accuracy                           0.93       109\n",
      "   macro avg       0.93      0.93      0.93       109\n",
      "weighted avg       0.93      0.93      0.93       109\n",
      "\n",
      "[[54  4]\n",
      " [ 4 47]]\n",
      "Kappa Score: 0.8526031102096011\n"
     ]
    }
   ],
   "source": [
    "grid_gbc_x_G1 = RandomizedSearchCV(gbc,param_distributions = parameters_gbc,refit=True,verbose=2,n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_gbc_x_G1.fit(X_train_x_G1,y_train_x_G1)\n",
    "print(grid_gbc_x_G1.best_estimator_)\n",
    "y_pred_x_G1= grid_gbc_x_G1.predict(X_test_x_G1)\n",
    "print(classification_report(y_pred_x_G1,y_test_x_G1,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_x_G1,y_pred_x_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G1,y_test_x_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 10 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   40.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.01, loss='deviance', max_depth=5,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.78      0.86        74\n",
      "           1       0.79      0.95      0.87        64\n",
      "\n",
      "    accuracy                           0.86       138\n",
      "   macro avg       0.87      0.87      0.86       138\n",
      "weighted avg       0.88      0.86      0.86       138\n",
      "\n",
      "[[58  3]\n",
      " [16 61]]\n",
      "Kappa Score: 0.726931889189752\n"
     ]
    }
   ],
   "source": [
    "grid_gbc_x_G3 = RandomizedSearchCV(gbc,param_distributions = parameters_gbc,refit=True,verbose=2,n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_gbc_x_G3.fit(X_train_x_G3,y_train_x_G3)\n",
    "print(grid_gbc_x_G3.best_estimator_)\n",
    "y_pred_x_G3= grid_gbc_x_G3.predict(X_test_x_G3)\n",
    "print(classification_report(y_pred_x_G3,y_test_x_G3,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_x_G3,y_pred_x_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G3,y_test_x_G3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 10 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=1,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89        17\n",
      "           1       1.00      0.78      0.88        18\n",
      "\n",
      "    accuracy                           0.89        35\n",
      "   macro avg       0.90      0.89      0.88        35\n",
      "weighted avg       0.91      0.89      0.88        35\n",
      "\n",
      "[[17  4]\n",
      " [ 0 14]]\n",
      "Kappa Score: 0.7727272727272727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    9.0s finished\n"
     ]
    }
   ],
   "source": [
    "grid_gbc_y_G1 = RandomizedSearchCV(gbc,param_distributions = parameters_gbc,refit=True,verbose=2,n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_gbc_y_G1.fit(X_train_y_G1,y_train_y_G1)\n",
    "print(grid_gbc_y_G1.best_estimator_)\n",
    "y_pred_y_G1= grid_gbc_y_G1.predict(X_test_y_G1)\n",
    "print(classification_report(y_pred_y_G1,y_test_y_G1,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_y_G1,y_pred_y_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G1,y_test_y_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 10 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.01, loss='deviance', max_depth=1,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        14\n",
      "           1       0.78      0.78      0.78         9\n",
      "\n",
      "    accuracy                           0.83        23\n",
      "   macro avg       0.82      0.82      0.82        23\n",
      "weighted avg       0.83      0.83      0.83        23\n",
      "\n",
      "[[12  2]\n",
      " [ 2  7]]\n",
      "Kappa Score: 0.6349206349206349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    4.4s finished\n"
     ]
    }
   ],
   "source": [
    "grid_gbc_y_G3 = RandomizedSearchCV(gbc,param_distributions = parameters_gbc,refit=True,verbose=2,n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_gbc_y_G3.fit(X_train_y_G3,y_train_y_G3)\n",
    "print(grid_gbc_y_G3.best_estimator_)\n",
    "y_pred_y_G3= grid_gbc_y_G3.predict(X_test_y_G3)\n",
    "print(classification_report(y_pred_y_G3,y_test_y_G3,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_y_G3,y_pred_y_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G3,y_test_y_G3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['l2']\n",
    "c_values = [10, 1.0, 0.1, 0.01]\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87        61\n",
      "           1       0.82      0.88      0.85        48\n",
      "\n",
      "    accuracy                           0.86       109\n",
      "   macro avg       0.86      0.86      0.86       109\n",
      "weighted avg       0.86      0.86      0.86       109\n",
      "\n",
      "[[52  6]\n",
      " [ 9 42]]\n",
      "Kappa Score: 0.72264631043257\n"
     ]
    }
   ],
   "source": [
    "grid_search_lr_x_G1 = RandomizedSearchCV(estimator=lr, param_distributions=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search_lr_x_G1.fit(X_train_x_G1,y_train_x_G1)\n",
    "print(grid_search_lr_x_G1.best_estimator_)\n",
    "y_pred_x_G1= grid_search_lr_x_G1.predict(X_test_x_G1)\n",
    "print(classification_report(y_pred_x_G1,y_test_x_G1,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_x_G1,y_pred_x_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G1,y_test_x_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.74      0.79        70\n",
      "           1       0.77      0.87      0.81        68\n",
      "\n",
      "    accuracy                           0.80       138\n",
      "   macro avg       0.81      0.81      0.80       138\n",
      "weighted avg       0.81      0.80      0.80       138\n",
      "\n",
      "[[52  9]\n",
      " [18 59]]\n",
      "Kappa Score: 0.6093520654225204\n"
     ]
    }
   ],
   "source": [
    "grid_search_lr_x_G3 = RandomizedSearchCV(estimator=lr, param_distributions=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search_lr_x_G3.fit(X_train_x_G3,y_train_x_G3)\n",
    "print(grid_search_lr_x_G3.best_estimator_)\n",
    "y_pred_x_G3= grid_search_lr_x_G3.predict(X_test_x_G3)\n",
    "print(classification_report(y_pred_x_G3,y_test_x_G3,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_x_G3,y_pred_x_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G3,y_test_x_G3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82        18\n",
      "           1       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.80        35\n",
      "   macro avg       0.81      0.80      0.80        35\n",
      "weighted avg       0.81      0.80      0.80        35\n",
      "\n",
      "[[16  5]\n",
      " [ 2 12]]\n",
      "Kappa Score: 0.5977011494252873\n"
     ]
    }
   ],
   "source": [
    "grid_search_lr_y_G1 = RandomizedSearchCV(estimator=lr, param_distributions=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search_lr_y_G1.fit(X_train_y_G1,y_train_y_G1)\n",
    "print(grid_search_lr_y_G1.best_estimator_)\n",
    "y_pred_y_G1= grid_search_lr_y_G1.predict(X_test_y_G1)\n",
    "print(classification_report(y_pred_y_G1,y_test_y_G1,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_y_G1,y_pred_y_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G1,y_test_y_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.87        16\n",
      "           1       0.67      0.86      0.75         7\n",
      "\n",
      "    accuracy                           0.83        23\n",
      "   macro avg       0.80      0.83      0.81        23\n",
      "weighted avg       0.85      0.83      0.83        23\n",
      "\n",
      "[[13  1]\n",
      " [ 3  6]]\n",
      "Kappa Score: 0.6198347107438017\n"
     ]
    }
   ],
   "source": [
    "grid_search_lr_y_G3 = RandomizedSearchCV(estimator=lr, param_distributions=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search_lr_y_G3.fit(X_train_y_G3,y_train_y_G3)\n",
    "print(grid_search_lr_y_G3.best_estimator_)\n",
    "y_pred_y_G3= grid_search_lr_y_G3.predict(X_test_y_G3)\n",
    "print(classification_report(y_pred_y_G3,y_test_y_G3,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_y_G3,y_pred_y_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G3,y_test_y_G3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models and parameters\n",
    "rf = RandomForestClassifier()\n",
    "n_estimators = [10, 100, 1000]\n",
    "max_features = ['sqrt', 'log2']\n",
    "# define grid search\n",
    "grid = dict(n_estimators=n_estimators,max_features=max_features)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='sqrt',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92        57\n",
      "           1       0.92      0.90      0.91        52\n",
      "\n",
      "    accuracy                           0.92       109\n",
      "   macro avg       0.92      0.92      0.92       109\n",
      "weighted avg       0.92      0.92      0.92       109\n",
      "\n",
      "[[53  5]\n",
      " [ 4 47]]\n",
      "Kappa Score: 0.8343744723957454\n"
     ]
    }
   ],
   "source": [
    "grid_search_rf_x_G1 = RandomizedSearchCV(estimator=rf, param_distributions=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search_rf_x_G1.fit(X_train_x_G1,y_train_x_G1)\n",
    "print(grid_search_rf_x_G1.best_estimator_)\n",
    "y_pred_x_G1= grid_search_rf_x_G1.predict(X_test_x_G1)\n",
    "print(classification_report(y_pred_x_G1,y_test_x_G1,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_x_G1,y_pred_x_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G1,y_test_x_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='sqrt',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.87        66\n",
      "           1       0.86      0.92      0.89        72\n",
      "\n",
      "    accuracy                           0.88       138\n",
      "   macro avg       0.88      0.88      0.88       138\n",
      "weighted avg       0.88      0.88      0.88       138\n",
      "\n",
      "[[55  6]\n",
      " [11 66]]\n",
      "Kappa Score: 0.7523749208359721\n"
     ]
    }
   ],
   "source": [
    "grid_search_rf_x_G3 = RandomizedSearchCV(estimator=rf, param_distributions=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search_rf_x_G3.fit(X_train_x_G3,y_train_x_G3)\n",
    "print(grid_search_rf_x_G3.best_estimator_)\n",
    "y_pred_x_G3= grid_search_rf_x_G3.predict(X_test_x_G3)\n",
    "print(classification_report(y_pred_x_G3,y_test_x_G3,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_x_G3,y_pred_x_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G3,y_test_x_G3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='log2',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89        17\n",
      "           1       1.00      0.78      0.88        18\n",
      "\n",
      "    accuracy                           0.89        35\n",
      "   macro avg       0.90      0.89      0.88        35\n",
      "weighted avg       0.91      0.89      0.88        35\n",
      "\n",
      "[[17  4]\n",
      " [ 0 14]]\n",
      "Kappa Score: 0.7727272727272727\n"
     ]
    }
   ],
   "source": [
    "grid_search_rf_y_G1 = RandomizedSearchCV(estimator=rf, param_distributions=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search_rf_y_G1.fit(X_train_y_G1,y_train_y_G1)\n",
    "print(grid_search_rf_y_G1.best_estimator_)\n",
    "y_pred_y_G1= grid_search_rf_y_G1.predict(X_test_y_G1)\n",
    "print(classification_report(y_pred_y_G1,y_test_y_G1,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_y_G1,y_pred_y_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G1,y_test_y_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='sqrt',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97        15\n",
      "           1       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.96        23\n",
      "   macro avg       0.94      0.97      0.95        23\n",
      "weighted avg       0.96      0.96      0.96        23\n",
      "\n",
      "[[14  0]\n",
      " [ 1  8]]\n",
      "Kappa Score: 0.9068825910931174\n"
     ]
    }
   ],
   "source": [
    "grid_search_rf_y_G3 = RandomizedSearchCV(estimator=rf, param_distributions=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search_rf_y_G3.fit(X_train_y_G3,y_train_y_G3)\n",
    "print(grid_search_rf_y_G3.best_estimator_)\n",
    "y_pred_y_G3= grid_search_rf_y_G3.predict(X_test_y_G3)\n",
    "print(classification_report(y_pred_y_G3,y_test_y_G3,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_y_G3,y_pred_y_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G3,y_test_y_G3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = DecisionTreeClassifier()\n",
    "param_dist = {\"max_depth\": [1,2,3,4,5],\n",
    "              \"max_features\": ['auto', 'sqrt', 'log2'],\n",
    "              \"min_samples_leaf\": [1,2,3,4,5],\n",
    "              \"min_samples_split\" : [1,2,3,4,5],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features='log2', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.78      0.68        45\n",
      "           1       0.80      0.64      0.71        64\n",
      "\n",
      "    accuracy                           0.70       109\n",
      "   macro avg       0.70      0.71      0.70       109\n",
      "weighted avg       0.72      0.70      0.70       109\n",
      "\n",
      "[[35 23]\n",
      " [10 41]]\n",
      "Kappa Score: 0.40119860163143006\n"
     ]
    }
   ],
   "source": [
    "grid_search_dct_x_G1 = RandomizedSearchCV(estimator=dct, param_distributions=param_dist, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search_dct_x_G1.fit(X_train_x_G1,y_train_x_G1)\n",
    "print(grid_search_dct_x_G1.best_estimator_)\n",
    "y_pred_x_G1= grid_search_dct_x_G1.predict(X_test_x_G1)\n",
    "print(classification_report(y_pred_x_G1,y_test_x_G1,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_x_G1,y_pred_x_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G1,y_test_x_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
      "                       max_depth=5, max_features='log2', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=4, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.55      0.64        88\n",
      "           1       0.48      0.74      0.58        50\n",
      "\n",
      "    accuracy                           0.62       138\n",
      "   macro avg       0.63      0.64      0.61       138\n",
      "weighted avg       0.68      0.62      0.62       138\n",
      "\n",
      "[[48 13]\n",
      " [40 37]]\n",
      "Kappa Score: 0.255648280073275\n"
     ]
    }
   ],
   "source": [
    "grid_search_dct_x_G3 = RandomizedSearchCV(estimator=dct, param_distributions=param_dist, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search_dct_x_G3.fit(X_train_x_G3,y_train_x_G3)\n",
    "print(grid_search_dct_x_G3.best_estimator_)\n",
    "y_pred_x_G3= grid_search_dct_x_G3.predict(X_test_x_G3)\n",
    "print(classification_report(y_pred_x_G3,y_test_x_G3,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_x_G3,y_pred_x_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G3,y_test_x_G3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
      "                       max_depth=5, max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=5, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.85      0.65        13\n",
      "           1       0.86      0.55      0.67        22\n",
      "\n",
      "    accuracy                           0.66        35\n",
      "   macro avg       0.69      0.70      0.66        35\n",
      "weighted avg       0.73      0.66      0.66        35\n",
      "\n",
      "[[11 10]\n",
      " [ 2 12]]\n",
      "Kappa Score: 0.34782608695652173\n"
     ]
    }
   ],
   "source": [
    "grid_search_dct_y_G1 = RandomizedSearchCV(estimator=dct, param_distributions=param_dist, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search_dct_y_G1.fit(X_train_y_G1,y_train_y_G1)\n",
    "print(grid_search_dct_y_G1.best_estimator_)\n",
    "y_pred_y_G1= grid_search_dct_y_G1.predict(X_test_y_G1)\n",
    "print(classification_report(y_pred_y_G1,y_test_y_G1,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_y_G1,y_pred_y_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G1,y_test_y_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
      "                       max_depth=5, max_features='log2', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=5, min_samples_split=5,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97        15\n",
      "           1       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.96        23\n",
      "   macro avg       0.94      0.97      0.95        23\n",
      "weighted avg       0.96      0.96      0.96        23\n",
      "\n",
      "[[14  0]\n",
      " [ 1  8]]\n",
      "Kappa Score: 0.9068825910931174\n"
     ]
    }
   ],
   "source": [
    "grid_search_dct_y_G3 = RandomizedSearchCV(estimator=dct, param_distributions=param_dist, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search_dct_y_G3.fit(X_train_y_G3,y_train_y_G3)\n",
    "print(grid_search_dct_y_G3.best_estimator_)\n",
    "y_pred_y_G3= grid_search_rf_y_G3.predict(X_test_y_G3)\n",
    "print(classification_report(y_pred_y_G3,y_test_y_G3,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_y_G3,y_pred_y_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G3,y_test_y_G3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87        59\n",
      "           1       0.84      0.86      0.85        50\n",
      "\n",
      "    accuracy                           0.86       109\n",
      "   macro avg       0.86      0.86      0.86       109\n",
      "weighted avg       0.86      0.86      0.86       109\n",
      "\n",
      "Kappa Score: 0.7233034354374683\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_x_G1,y_train_x_G1)\n",
    "y_pred_x_G1= clf.predict(X_test_x_G1)\n",
    "print(classification_report(y_pred_x_G1,y_test_x_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G1,y_test_x_G1)))\n",
    "probagnbG1x = clf.predict_proba(X_test_x_G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.73      0.79        71\n",
      "           1       0.75      0.87      0.81        67\n",
      "\n",
      "    accuracy                           0.80       138\n",
      "   macro avg       0.80      0.80      0.80       138\n",
      "weighted avg       0.80      0.80      0.80       138\n",
      "\n",
      "Kappa Score: 0.5955620682436675\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_x_G3,y_train_x_G3)\n",
    "y_pred_x_G3= clf.predict(X_test_x_G3)\n",
    "print(classification_report(y_pred_x_G3,y_test_x_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G3,y_test_x_G3)))\n",
    "probagnbG3x = clf.predict_proba(X_test_x_G3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.80        19\n",
      "           1       0.79      0.69      0.73        16\n",
      "\n",
      "    accuracy                           0.77        35\n",
      "   macro avg       0.77      0.76      0.77        35\n",
      "weighted avg       0.77      0.77      0.77        35\n",
      "\n",
      "Kappa Score: 0.5348837209302326\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_y_G1,y_train_y_G1)\n",
    "y_pred_y_G1 = clf.predict(X_test_y_G1)\n",
    "print(classification_report(y_pred_y_G1,y_test_y_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G1,y_test_y_G1)))\n",
    "probagnbG1y = clf.predict_proba(X_test_y_G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71        14\n",
      "           1       0.56      0.56      0.56         9\n",
      "\n",
      "    accuracy                           0.65        23\n",
      "   macro avg       0.63      0.63      0.63        23\n",
      "weighted avg       0.65      0.65      0.65        23\n",
      "\n",
      "Kappa Score: 0.2698412698412699\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_y_G3,y_train_y_G3)\n",
    "y_pred_y_G3 = clf.predict(X_test_y_G3)\n",
    "print(classification_report(y_pred_y_G3,y_test_y_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G3,y_test_y_G3)))\n",
    "probagnbG3y = clf.predict_proba(X_test_y_G3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
