{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "probadf = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_combined_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel.y</th>\n",
       "      <th>freetime.y</th>\n",
       "      <th>goout.y</th>\n",
       "      <th>Dalc.y</th>\n",
       "      <th>Walc.y</th>\n",
       "      <th>health.y</th>\n",
       "      <th>absences.y</th>\n",
       "      <th>G1.y</th>\n",
       "      <th>G2.y</th>\n",
       "      <th>G3.y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   school  sex  age  address  famsize  Pstatus  Medu  Fedu  Mjob  Fjob  ...  \\\n",
       "0       0    0   15        0        0        1     1     1     0     2  ...   \n",
       "1       0    0   15        0        0        1     1     1     2     2  ...   \n",
       "2       0    0   15        0        0        1     2     2     0     2  ...   \n",
       "3       0    0   15        0        0        1     2     4     3     1  ...   \n",
       "4       0    0   15        0        0        1     3     3     3     3  ...   \n",
       "\n",
       "   famrel.y  freetime.y  goout.y  Dalc.y  Walc.y  health.y  absences.y  G1.y  \\\n",
       "0         3           1        2       1       1         1           4    13   \n",
       "1         3           3        4       2       4         5           2    13   \n",
       "2         4           3        1       1       1         2           8    14   \n",
       "3         4           3        2       1       1         5           2    10   \n",
       "4         4           2        1       2       3         3           2    13   \n",
       "\n",
       "   G2.y  G3.y  \n",
       "0    13    13  \n",
       "1    11    11  \n",
       "2    13    12  \n",
       "3    11    10  \n",
       "4    13    13  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {'Unnamed: 0':'ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
       "       'Mjob', 'Fjob', 'reason', 'nursery', 'internet', 'guardian.x',\n",
       "       'traveltime.x', 'studytime.x', 'failures.x', 'schoolsup.x', 'famsup.x',\n",
       "       'paid.x', 'activities.x', 'higher.x', 'romantic.x', 'famrel.x',\n",
       "       'freetime.x', 'goout.x', 'Dalc.x', 'Walc.x', 'health.x', 'absences.x',\n",
       "       'G1.x', 'G2.x', 'G3.x', 'guardian.y', 'traveltime.y', 'studytime.y',\n",
       "       'failures.y', 'schoolsup.y', 'famsup.y', 'paid.y', 'activities.y',\n",
       "       'higher.y', 'romantic.y', 'famrel.y', 'freetime.y', 'goout.y', 'Dalc.y',\n",
       "       'Walc.y', 'health.y', 'absences.y', 'G1.y', 'G2.y', 'G3.y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfeatures=['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
    "       'Mjob', 'Fjob', 'reason', 'nursery', 'internet', 'guardian.x',\n",
    "       'traveltime.x', 'studytime.x', 'failures.x', 'schoolsup.x', 'famsup.x',\n",
    "       'paid.x', 'activities.x', 'higher.x', 'romantic.x', 'famrel.x',\n",
    "       'freetime.x', 'goout.x', 'Dalc.x', 'Walc.x', 'health.x', 'absences.x','G1.x','G3.x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "yfeatures = ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
    "       'Mjob', 'Fjob', 'reason', 'nursery', 'internet','guardian.y', 'traveltime.y', 'studytime.y',\n",
    "       'failures.y', 'schoolsup.y', 'famsup.y', 'paid.y', 'activities.y',\n",
    "       'higher.y', 'romantic.y', 'famrel.y', 'freetime.y', 'goout.y', 'Dalc.y',\n",
    "       'Walc.y', 'health.y', 'absences.y','G1.y','G3.y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "keepcol = ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu',\n",
    "       'Fedu', 'Mjob', 'Fjob', 'reason', 'nursery', 'internet', 'guardian.x',\n",
    "       'traveltime.x', 'studytime.x', 'failures.x', 'schoolsup.x', 'famsup.x',\n",
    "       'paid.x', 'activities.x', 'higher.x', 'romantic.x', 'famrel.x',\n",
    "       'freetime.x', 'goout.x', 'Dalc.x', 'Walc.x', 'health.x', 'absences.x',\n",
    "       'G1.x', 'G2.x', 'G3.x', 'guardian.y', 'traveltime.y', 'studytime.y',\n",
    "       'failures.y', 'schoolsup.y', 'famsup.y', 'paid.y', 'activities.y',\n",
    "       'higher.y', 'romantic.y', 'famrel.y', 'freetime.y', 'goout.y', 'Dalc.y',\n",
    "       'Walc.y', 'health.y', 'absences.y', 'G1.y', 'G2.y', 'G3.y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fildf = df.loc[:,keepcol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fildf_x = fildf.loc[:,xfeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fildf_y = fildf.loc[:,yfeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(882, 32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fildf_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(882, 32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fildf_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertmarks(mark):\n",
    "    if mark<10:\n",
    "        return 'F'\n",
    "    elif mark==10 or mark==11:\n",
    "        return 'D'\n",
    "    elif mark==12 or mark==13:\n",
    "        return 'C'\n",
    "    elif mark==14 or mark==15:\n",
    "        return'B'\n",
    "    else:\n",
    "        return 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlist=[]\n",
    "for i in fildf_x['G1.x']:\n",
    "    x = convertmarks(i)\n",
    "    newlist.append(x)\n",
    "fildf_x['New G1'] = newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlist=[]\n",
    "for i in fildf_y['G1.y']:\n",
    "    x = convertmarks(i)\n",
    "    newlist.append(x)\n",
    "fildf_y['New G1'] = newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlist=[]\n",
    "for i in fildf_x['G3.x']:\n",
    "    x = convertmarks(i)\n",
    "    newlist.append(x)\n",
    "fildf_x['New G3'] = newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlist=[]\n",
    "for i in fildf_y['G3.y']:\n",
    "    x = convertmarks(i)\n",
    "    newlist.append(x)\n",
    "fildf_y['New G3'] = newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      C\n",
       "1      D\n",
       "2      C\n",
       "3      D\n",
       "4      C\n",
       "      ..\n",
       "877    C\n",
       "878    B\n",
       "879    C\n",
       "880    C\n",
       "881    C\n",
       "Name: New G3, Length: 882, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fildf_y['New G3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fildf_x['New G1']= label_encoder.fit_transform(fildf_x['New G1'])\n",
    "fildf_y['New G1']= label_encoder.fit_transform(fildf_y['New G1'])\n",
    "fildf_x['New G3']= label_encoder.fit_transform(fildf_x['New G3'])\n",
    "fildf_y['New G3']= label_encoder.fit_transform(fildf_y['New G3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2\n",
       "1      3\n",
       "2      2\n",
       "3      3\n",
       "4      2\n",
       "      ..\n",
       "877    2\n",
       "878    1\n",
       "879    2\n",
       "880    2\n",
       "881    2\n",
       "Name: New G3, Length: 882, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fildf_y['New G3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fildf_x = fildf_x.sample(frac=1,random_state=123)\n",
    "fildf_y = fildf_y.sample(frac=1,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fildf_x = fildf_x.drop(['G1.x','G3.x'],axis=1)\n",
    "fildf_y = fildf_y.drop(['G1.y','G3.y'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_x_G3 = fildf_x.drop(['New G1','New G3'],axis=1)\n",
    "features_x_G1 = fildf_x.drop(['New G1','New G3'],axis=1)\n",
    "features_y_G3 = fildf_y.drop(['New G1','New G3'],axis=1)\n",
    "features_y_G1 = fildf_y.drop(['New G1','New G3'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_x_G3 = fildf_x['New G3']\n",
    "target_x_G1 = fildf_x['New G1']\n",
    "target_y_G3 = fildf_y['New G3']\n",
    "target_y_G1 = fildf_y['New G1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_x_G1, X_test_x_G1, y_train_x_G1, y_test_x_G1 = train_test_split(features_x_G1, target_x_G1, test_size=0.25, random_state=0)\n",
    "X_train_y_G1, X_test_y_G1, y_train_y_G1, y_test_y_G1 = train_test_split(features_y_G1, target_y_G1, test_size=0.25, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(661, 30)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_x_G1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_x_G3, X_test_x_G3, y_train_x_G3, y_test_x_G3 = train_test_split(features_x_G3, target_x_G3, test_size=0.25, random_state=0)\n",
    "X_train_y_G3, X_test_y_G3, y_train_y_G3, y_test_y_G3 = train_test_split(features_y_G3, target_y_G3, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221, 30)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_y_G3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function\n",
    "def select_n_components(var_ratio, goal_var: float) -> int:\n",
    "    # Set initial variance explained so far\n",
    "    total_variance = 0.0\n",
    "    \n",
    "    # Set initial number of features\n",
    "    n_components = 0\n",
    "    \n",
    "    # For the explained variance of each feature:\n",
    "    for explained_variance in var_ratio:\n",
    "        \n",
    "        # Add the explained variance to the total\n",
    "        total_variance += explained_variance\n",
    "        \n",
    "        # Add one to the number of components\n",
    "        n_components += 1\n",
    "        \n",
    "        # If we reach our goal level of explained variance\n",
    "        if total_variance >= goal_var:\n",
    "            # End the loop\n",
    "            break\n",
    "            \n",
    "    # Return the number of components\n",
    "    return n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda1 = LinearDiscriminantAnalysis(n_components=None)\n",
    "X_train_x_G1 = lda1.fit_transform(X_train_x_G1,y_train_x_G1)\n",
    "X_test_x_G1 = lda1.transform(X_test_x_G1)\n",
    "lda1_var_ratios = lda1.explained_variance_ratio_\n",
    "num1 = select_n_components(lda1_var_ratios, 0.95)\n",
    "lda1 = LinearDiscriminantAnalysis(n_components=num1)\n",
    "X_train_x_G1 = lda1.fit_transform(X_train_x_G1,y_train_x_G1)\n",
    "X_test_x_G1 = lda1.transform(X_test_x_G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(661, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_x_G1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda2 = LinearDiscriminantAnalysis(n_components=None)\n",
    "X_train_x_G3 = lda2.fit_transform(X_train_x_G3,y_train_x_G3)\n",
    "X_test_x_G3 = lda2.transform(X_test_x_G3)\n",
    "lda2_var_ratios = lda2.explained_variance_ratio_\n",
    "num2 = select_n_components(lda2_var_ratios, 0.95)\n",
    "lda2 = LinearDiscriminantAnalysis(n_components=num2)\n",
    "X_train_x_G3 = lda2.fit_transform(X_train_x_G3,y_train_x_G3)\n",
    "X_test_x_G3 = lda2.transform(X_test_x_G3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda3 = LinearDiscriminantAnalysis(n_components=None)\n",
    "X_train_y_G1 = lda3.fit_transform(X_train_y_G1,y_train_y_G1)\n",
    "X_test_y_G1 = lda3.transform(X_test_y_G1)\n",
    "lda3_var_ratios = lda3.explained_variance_ratio_\n",
    "num3 = select_n_components(lda3_var_ratios, 0.95)\n",
    "lda3 = LinearDiscriminantAnalysis(n_components=num3)\n",
    "X_train_y_G1 = lda3.fit_transform(X_train_y_G1,y_train_y_G1)\n",
    "X_test_y_G1 = lda3.transform(X_test_y_G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda4 = LinearDiscriminantAnalysis(n_components=None)\n",
    "X_train_y_G3 = lda4.fit_transform(X_train_y_G3,y_train_y_G3)\n",
    "X_test_y_G3 = lda4.transform(X_test_y_G3)\n",
    "lda4_var_ratios = lda4.explained_variance_ratio_\n",
    "num4 = select_n_components(lda4_var_ratios, 0.95)\n",
    "lda4 = LinearDiscriminantAnalysis(n_components=num3)\n",
    "X_train_y_G3 = lda4.fit_transform(X_train_y_G3,y_train_y_G3)\n",
    "X_test_y_G3 = lda4.transform(X_test_y_G3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_y_G3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.96      0.61      0.74       163\n",
      "           3       0.36      0.68      0.47        19\n",
      "           4       0.53      0.94      0.68        33\n",
      "\n",
      "    accuracy                           0.65       221\n",
      "   macro avg       0.37      0.45      0.38       221\n",
      "weighted avg       0.82      0.65      0.69       221\n",
      "\n",
      "Kappa Score: 0.4130745658835546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_x_G1,y_train_x_G1)\n",
    "y_pred_x_G1= clf.predict(X_test_x_G1)\n",
    "print(classification_report(y_pred_x_G1,y_test_x_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G1,y_test_x_G1)))\n",
    "probagnbG1x = clf.predict_proba(X_test_x_G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.96      0.59      0.73       165\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.63      0.90      0.74        50\n",
      "\n",
      "    accuracy                           0.65       221\n",
      "   macro avg       0.32      0.30      0.30       221\n",
      "weighted avg       0.86      0.65      0.72       221\n",
      "\n",
      "Kappa Score: 0.3922792173453199\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_x_G3,y_train_x_G3)\n",
    "y_pred_x_G3= clf.predict(X_test_x_G3)\n",
    "print(classification_report(y_pred_x_G3,y_test_x_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G3,y_test_x_G3)))\n",
    "probagnbG3x = clf.predict_proba(X_test_x_G3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.40      0.60      0.48        20\n",
      "           2       0.86      0.68      0.76       142\n",
      "           3       0.56      0.67      0.61        46\n",
      "           4       0.46      0.46      0.46        13\n",
      "\n",
      "    accuracy                           0.66       221\n",
      "   macro avg       0.46      0.48      0.46       221\n",
      "weighted avg       0.73      0.66      0.69       221\n",
      "\n",
      "Kappa Score: 0.4380593978844588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_y_G1,y_train_y_G1)\n",
    "y_pred_y_G1 = clf.predict(X_test_y_G1)\n",
    "print(classification_report(y_pred_y_G1,y_test_y_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G1,y_test_y_G1)))\n",
    "probagnbG1y = clf.predict_proba(X_test_y_G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.75      0.29         4\n",
      "           1       0.58      0.49      0.53        57\n",
      "           2       0.71      0.59      0.64       113\n",
      "           3       0.49      0.68      0.57        37\n",
      "           4       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.58       221\n",
      "   macro avg       0.51      0.62      0.53       221\n",
      "weighted avg       0.62      0.58      0.59       221\n",
      "\n",
      "Kappa Score: 0.3897043373855621\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_y_G3,y_train_y_G3)\n",
    "y_pred_y_G3 = clf.predict(X_test_y_G3)\n",
    "print(classification_report(y_pred_y_G3,y_test_y_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G3,y_test_y_G3)))\n",
    "probagnbG3y = clf.predict_proba(X_test_y_G3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.13      0.16        15\n",
      "           1       0.36      0.36      0.36        14\n",
      "           2       0.59      0.63      0.61        97\n",
      "           3       0.28      0.24      0.26        42\n",
      "           4       0.53      0.58      0.56        53\n",
      "\n",
      "    accuracy                           0.49       221\n",
      "   macro avg       0.39      0.39      0.39       221\n",
      "weighted avg       0.48      0.49      0.48       221\n",
      "\n",
      "Kappa Score: 0.27023999056548154\n"
     ]
    }
   ],
   "source": [
    "imp_dict={}\n",
    "dtc.fit(X_train_x_G1,y_train_x_G1)\n",
    "y_pred_x_G1= dtc.predict(X_test_x_G1)\n",
    "probadtcG1x = dtc.predict_proba(X_test_x_G1)\n",
    "print(classification_report(y_pred_x_G1,y_test_x_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G1,y_test_x_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.33      0.29         9\n",
      "           1       0.07      0.08      0.07        12\n",
      "           2       0.60      0.58      0.59       105\n",
      "           3       0.10      0.06      0.08        32\n",
      "           4       0.61      0.68      0.64        63\n",
      "\n",
      "    accuracy                           0.50       221\n",
      "   macro avg       0.32      0.35      0.33       221\n",
      "weighted avg       0.48      0.50      0.49       221\n",
      "\n",
      "Kappa Score: 0.2497706281729769\n"
     ]
    }
   ],
   "source": [
    "imp_dict={}\n",
    "dtc.fit(X_train_x_G3,y_train_x_G3)\n",
    "y_pred_x_G3= dtc.predict(X_test_x_G3)\n",
    "probadtcG3x = dtc.predict_proba(X_test_x_G3)\n",
    "print(classification_report(y_pred_x_G3,y_test_x_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G3,y_test_x_G3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.29      0.33        14\n",
      "           1       0.40      0.34      0.37        35\n",
      "           2       0.64      0.69      0.66       105\n",
      "           3       0.60      0.62      0.61        53\n",
      "           4       0.46      0.43      0.44        14\n",
      "\n",
      "    accuracy                           0.57       221\n",
      "   macro avg       0.50      0.47      0.48       221\n",
      "weighted avg       0.56      0.57      0.57       221\n",
      "\n",
      "Kappa Score: 0.36449570191807645\n"
     ]
    }
   ],
   "source": [
    "imp_dict={}\n",
    "dtc.fit(X_train_y_G1,y_train_y_G1)\n",
    "y_pred_y_G1 = dtc.predict(X_test_y_G1)\n",
    "probadtcG1y = dtc.predict_proba(X_test_y_G1)\n",
    "print(classification_report(y_pred_y_G1,y_test_y_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G1,y_test_y_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.22      0.25        23\n",
      "           1       0.35      0.35      0.35        49\n",
      "           2       0.55      0.58      0.57        89\n",
      "           3       0.55      0.52      0.53        54\n",
      "           4       0.40      0.67      0.50         6\n",
      "\n",
      "    accuracy                           0.48       221\n",
      "   macro avg       0.43      0.47      0.44       221\n",
      "weighted avg       0.47      0.48      0.48       221\n",
      "\n",
      "Kappa Score: 0.27029199804760407\n"
     ]
    }
   ],
   "source": [
    "imp_dict={}\n",
    "dtc.fit(X_train_y_G3,y_train_y_G3)\n",
    "y_pred_y_G3 = dtc.predict(X_test_y_G3)\n",
    "probadtcG3y = dtc.predict_proba(X_test_y_G3)\n",
    "print(classification_report(y_pred_y_G3,y_test_y_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G3,y_test_y_G3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.50      0.37         6\n",
      "           1       0.14      0.25      0.18         8\n",
      "           2       0.87      0.61      0.72       148\n",
      "           3       0.22      0.53      0.31        15\n",
      "           4       0.55      0.73      0.63        44\n",
      "\n",
      "    accuracy                           0.61       221\n",
      "   macro avg       0.42      0.52      0.44       221\n",
      "weighted avg       0.72      0.61      0.64       221\n",
      "\n",
      "Kappa Score: 0.37342168595259284\n"
     ]
    }
   ],
   "source": [
    "imp_dict={}\n",
    "rf.fit(X_train_x_G1,y_train_x_G1)\n",
    "y_pred_x_G1= rf.predict(X_test_x_G1)\n",
    "probarfG1x = rf.predict_proba(X_test_x_G1)\n",
    "\n",
    "print(classification_report(y_pred_x_G1,y_test_x_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G1,y_test_x_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.33      0.22         6\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.83      0.59      0.69       145\n",
      "           3       0.05      0.14      0.07         7\n",
      "           4       0.66      0.82      0.73        57\n",
      "\n",
      "    accuracy                           0.61       221\n",
      "   macro avg       0.34      0.38      0.34       221\n",
      "weighted avg       0.72      0.61      0.65       221\n",
      "\n",
      "Kappa Score: 0.3599595891564237\n"
     ]
    }
   ],
   "source": [
    "imp_dict={}\n",
    "rf.fit(X_train_x_G3,y_train_x_G3)\n",
    "y_pred_x_G3= rf.predict(X_test_x_G3)\n",
    "probarfG3x = rf.predict_proba(X_test_x_G3)\n",
    "\n",
    "print(classification_report(y_pred_x_G3,y_test_x_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G3,y_test_x_G3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      1.00      0.18         1\n",
      "           1       0.57      0.53      0.55        32\n",
      "           2       0.85      0.75      0.80       128\n",
      "           3       0.64      0.73      0.68        48\n",
      "           4       0.62      0.67      0.64        12\n",
      "\n",
      "    accuracy                           0.71       221\n",
      "   macro avg       0.55      0.74      0.57       221\n",
      "weighted avg       0.75      0.71      0.72       221\n",
      "\n",
      "Kappa Score: 0.5379438763843063\n"
     ]
    }
   ],
   "source": [
    "imp_dict={}\n",
    "rf.fit(X_train_y_G1,y_train_y_G1)\n",
    "y_pred_y_G1 = rf.predict(X_test_y_G1)\n",
    "probarfG1y = rf.predict_proba(X_test_y_G1)\n",
    "\n",
    "print(classification_report(y_pred_y_G1,y_test_y_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G1,y_test_y_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.27      0.21        11\n",
      "           1       0.54      0.49      0.51        53\n",
      "           2       0.69      0.59      0.64       111\n",
      "           3       0.49      0.61      0.54        41\n",
      "           4       0.40      0.80      0.53         5\n",
      "\n",
      "    accuracy                           0.56       221\n",
      "   macro avg       0.46      0.55      0.49       221\n",
      "weighted avg       0.59      0.56      0.57       221\n",
      "\n",
      "Kappa Score: 0.3586345141215893\n"
     ]
    }
   ],
   "source": [
    "imp_dict={}\n",
    "rf.fit(X_train_y_G3,y_train_y_G3)\n",
    "y_pred_y_G3 = rf.predict(X_test_y_G3)\n",
    "probarfG3y = rf.predict_proba(X_test_y_G3)\n",
    "print(classification_report(y_pred_y_G3,y_test_y_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G3,y_test_y_G3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "lsvm = svm.SVC(kernel='linear', probability = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.99      0.60      0.74       171\n",
      "           3       0.28      0.67      0.39        15\n",
      "           4       0.53      0.89      0.67        35\n",
      "\n",
      "    accuracy                           0.65       221\n",
      "   macro avg       0.36      0.43      0.36       221\n",
      "weighted avg       0.87      0.65      0.71       221\n",
      "\n",
      "Kappa Score: 0.39849256752041307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "lsvm.fit(X_train_x_G1,y_train_x_G1)\n",
    "y_pred_x_G1= lsvm.predict(X_test_x_G1)\n",
    "probalsvmG1x = lsvm.predict_proba(X_test_x_G1)\n",
    "\n",
    "print(classification_report(y_pred_x_G1,y_test_x_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G1,y_test_x_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.99      0.59      0.74       170\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.65      0.90      0.75        51\n",
      "\n",
      "    accuracy                           0.67       221\n",
      "   macro avg       0.33      0.30      0.30       221\n",
      "weighted avg       0.91      0.67      0.75       221\n",
      "\n",
      "Kappa Score: 0.4134146341463415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "lsvm.fit(X_train_x_G3,y_train_x_G3)\n",
    "y_pred_x_G3= lsvm.predict(X_test_x_G3)\n",
    "probalsvmG3x = lsvm.predict_proba(X_test_x_G3)\n",
    "\n",
    "print(classification_report(y_pred_x_G3,y_test_x_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G3,y_test_x_G3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.37      0.79      0.50        14\n",
      "           2       0.93      0.68      0.79       154\n",
      "           3       0.56      0.72      0.63        43\n",
      "           4       0.46      0.60      0.52        10\n",
      "\n",
      "    accuracy                           0.69       221\n",
      "   macro avg       0.46      0.56      0.49       221\n",
      "weighted avg       0.80      0.69      0.73       221\n",
      "\n",
      "Kappa Score: 0.4731454213995231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "lsvm.fit(X_train_y_G1,y_train_y_G1)\n",
    "y_pred_y_G1 = lsvm.predict(X_test_y_G1)\n",
    "probalsvmG1y = lsvm.predict_proba(X_test_y_G1)\n",
    "\n",
    "print(classification_report(y_pred_y_G1,y_test_y_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G1,y_test_y_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.60      0.48      0.54        60\n",
      "           2       0.74      0.60      0.66       116\n",
      "           3       0.55      0.72      0.62        39\n",
      "           4       0.40      0.67      0.50         6\n",
      "\n",
      "    accuracy                           0.59       221\n",
      "   macro avg       0.46      0.49      0.46       221\n",
      "weighted avg       0.66      0.59      0.62       221\n",
      "\n",
      "Kappa Score: 0.3952936884348778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "lsvm.fit(X_train_y_G3,y_train_y_G3)\n",
    "y_pred_y_G3 = lsvm.predict(X_test_y_G3)\n",
    "probalsvmG3y = lsvm.predict_proba(X_test_y_G3)\n",
    "print(classification_report(y_pred_y_G3,y_test_y_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G3,y_test_y_G3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression(random_state=0,max_iter=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.97      0.59      0.74       169\n",
      "           3       0.28      0.67      0.39        15\n",
      "           4       0.53      0.89      0.67        35\n",
      "\n",
      "    accuracy                           0.64       221\n",
      "   macro avg       0.36      0.43      0.36       221\n",
      "weighted avg       0.85      0.64      0.69       221\n",
      "\n",
      "Kappa Score: 0.38687751421833816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "lg.fit(X_train_x_G1,y_train_x_G1)\n",
    "y_pred_x_G1= lg.predict(X_test_x_G1)\n",
    "probalgG1x = lg.predict_proba(X_test_x_G1)\n",
    "\n",
    "print(classification_report(y_pred_x_G1,y_test_x_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G1,y_test_x_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.98      0.60      0.74       167\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.66      0.90      0.76        52\n",
      "\n",
      "    accuracy                           0.67       221\n",
      "   macro avg       0.33      0.30      0.30       221\n",
      "weighted avg       0.90      0.67      0.74       221\n",
      "\n",
      "Kappa Score: 0.41769627915257257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "lg.fit(X_train_x_G3,y_train_x_G3)\n",
    "y_pred_x_G3= lg.predict(X_test_x_G3)\n",
    "probalgG3x = lg.predict_proba(X_test_x_G3)\n",
    "\n",
    "print(classification_report(y_pred_x_G3,y_test_x_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G3,y_test_x_G3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.33      0.59      0.43        17\n",
      "           2       0.89      0.66      0.76       154\n",
      "           3       0.51      0.72      0.60        39\n",
      "           4       0.54      0.64      0.58        11\n",
      "\n",
      "    accuracy                           0.66       221\n",
      "   macro avg       0.45      0.52      0.47       221\n",
      "weighted avg       0.77      0.66      0.69       221\n",
      "\n",
      "Kappa Score: 0.42128417303865096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "lg.fit(X_train_y_G1,y_train_y_G1)\n",
    "y_pred_y_G1 = lg.predict(X_test_y_G1)\n",
    "probalgG1y = lg.predict_proba(X_test_y_G1)\n",
    "\n",
    "print(classification_report(y_pred_y_G1,y_test_y_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G1,y_test_y_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.52      0.45      0.49        55\n",
      "           2       0.75      0.59      0.66       120\n",
      "           3       0.55      0.74      0.63        38\n",
      "           4       0.50      0.62      0.56         8\n",
      "\n",
      "    accuracy                           0.58       221\n",
      "   macro avg       0.46      0.48      0.47       221\n",
      "weighted avg       0.65      0.58      0.61       221\n",
      "\n",
      "Kappa Score: 0.37980050636000373\n"
     ]
    }
   ],
   "source": [
    "lg.fit(X_train_y_G3,y_train_y_G3)\n",
    "y_pred_y_G3 = lg.predict(X_test_y_G3)\n",
    "probalgG3y = lg.predict_proba(X_test_y_G3)\n",
    "print(classification_report(y_pred_y_G3,y_test_y_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G3,y_test_y_G3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.25      0.22         8\n",
      "           1       0.14      0.40      0.21         5\n",
      "           2       0.86      0.64      0.73       140\n",
      "           3       0.31      0.46      0.37        24\n",
      "           4       0.57      0.75      0.65        44\n",
      "\n",
      "    accuracy                           0.62       221\n",
      "   macro avg       0.42      0.50      0.44       221\n",
      "weighted avg       0.70      0.62      0.65       221\n",
      "\n",
      "Kappa Score: 0.3983471074380165\n"
     ]
    }
   ],
   "source": [
    "gb.fit(X_train_x_G1,y_train_x_G1)\n",
    "y_pred_x_G1= gb.predict(X_test_x_G1)\n",
    "probagbG1x = gb.predict_proba(X_test_x_G1)\n",
    "print(classification_report(y_pred_x_G1,y_test_x_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G1,y_test_x_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.43      0.32         7\n",
      "           1       0.07      0.11      0.08         9\n",
      "           2       0.85      0.62      0.72       140\n",
      "           3       0.05      0.08      0.06        13\n",
      "           4       0.56      0.77      0.65        52\n",
      "\n",
      "    accuracy                           0.60       221\n",
      "   macro avg       0.36      0.40      0.37       221\n",
      "weighted avg       0.69      0.60      0.63       221\n",
      "\n",
      "Kappa Score: 0.35250353886163877\n"
     ]
    }
   ],
   "source": [
    "gb.fit(X_train_x_G3,y_train_x_G3)\n",
    "y_pred_x_G3= gb.predict(X_test_x_G3)\n",
    "\n",
    "probagbG3x = gb.predict_proba(X_test_x_G3)\n",
    "print(classification_report(y_pred_x_G3,y_test_x_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G3,y_test_x_G3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.33      0.25         6\n",
      "           1       0.37      0.46      0.41        24\n",
      "           2       0.81      0.69      0.74       132\n",
      "           3       0.47      0.60      0.53        43\n",
      "           4       0.54      0.44      0.48        16\n",
      "\n",
      "    accuracy                           0.62       221\n",
      "   macro avg       0.48      0.50      0.48       221\n",
      "weighted avg       0.66      0.62      0.63       221\n",
      "\n",
      "Kappa Score: 0.3927777050896245\n"
     ]
    }
   ],
   "source": [
    "gb.fit(X_train_y_G1,y_train_y_G1)\n",
    "y_pred_y_G1 = gb.predict(X_test_y_G1)\n",
    "\n",
    "probagbG1y = gb.predict_proba(X_test_y_G1)\n",
    "print(classification_report(y_pred_y_G1,y_test_y_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G1,y_test_y_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.33      0.28        12\n",
      "           1       0.52      0.45      0.48        56\n",
      "           2       0.69      0.64      0.67       103\n",
      "           3       0.47      0.65      0.55        37\n",
      "           4       0.60      0.46      0.52        13\n",
      "\n",
      "    accuracy                           0.57       221\n",
      "   macro avg       0.50      0.51      0.50       221\n",
      "weighted avg       0.58      0.57      0.57       221\n",
      "\n",
      "Kappa Score: 0.37868626819339923\n"
     ]
    }
   ],
   "source": [
    "gb.fit(X_train_y_G3,y_train_y_G3)\n",
    "y_pred_y_G3 = gb.predict(X_test_y_G3)\n",
    "\n",
    "probagbG3y = gb.predict_proba(X_test_y_G3)\n",
    "print(classification_report(y_pred_y_G3,y_test_y_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G3,y_test_y_G3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
