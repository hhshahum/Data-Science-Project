{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import rankdata\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_combined_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel.y</th>\n",
       "      <th>freetime.y</th>\n",
       "      <th>goout.y</th>\n",
       "      <th>Dalc.y</th>\n",
       "      <th>Walc.y</th>\n",
       "      <th>health.y</th>\n",
       "      <th>absences.y</th>\n",
       "      <th>G1.y</th>\n",
       "      <th>G2.y</th>\n",
       "      <th>G3.y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   school  sex  age  address  famsize  Pstatus  Medu  Fedu  Mjob  Fjob  ...  \\\n",
       "0       0    0   15        0        0        1     1     1     0     2  ...   \n",
       "1       0    0   15        0        0        1     1     1     2     2  ...   \n",
       "2       0    0   15        0        0        1     2     2     0     2  ...   \n",
       "3       0    0   15        0        0        1     2     4     3     1  ...   \n",
       "4       0    0   15        0        0        1     3     3     3     3  ...   \n",
       "\n",
       "   famrel.y  freetime.y  goout.y  Dalc.y  Walc.y  health.y  absences.y  G1.y  \\\n",
       "0         3           1        2       1       1         1           4    13   \n",
       "1         3           3        4       2       4         5           2    13   \n",
       "2         4           3        1       1       1         2           8    14   \n",
       "3         4           3        2       1       1         5           2    10   \n",
       "4         4           2        1       2       3         3           2    13   \n",
       "\n",
       "   G2.y  G3.y  \n",
       "0    13    13  \n",
       "1    11    11  \n",
       "2    13    12  \n",
       "3    11    10  \n",
       "4    13    13  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {'Unnamed: 0':'ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
       "       'Mjob', 'Fjob', 'reason', 'nursery', 'internet', 'guardian.x',\n",
       "       'traveltime.x', 'studytime.x', 'failures.x', 'schoolsup.x', 'famsup.x',\n",
       "       'paid.x', 'activities.x', 'higher.x', 'romantic.x', 'famrel.x',\n",
       "       'freetime.x', 'goout.x', 'Dalc.x', 'Walc.x', 'health.x', 'absences.x',\n",
       "       'G1.x', 'G2.x', 'G3.x', 'guardian.y', 'traveltime.y', 'studytime.y',\n",
       "       'failures.y', 'schoolsup.y', 'famsup.y', 'paid.y', 'activities.y',\n",
       "       'higher.y', 'romantic.y', 'famrel.y', 'freetime.y', 'goout.y', 'Dalc.y',\n",
       "       'Walc.y', 'health.y', 'absences.y', 'G1.y', 'G2.y', 'G3.y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfeatures=['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
    "       'Mjob', 'Fjob', 'reason', 'nursery', 'internet', 'guardian.x',\n",
    "       'traveltime.x', 'studytime.x', 'failures.x', 'schoolsup.x', 'famsup.x',\n",
    "       'paid.x', 'activities.x', 'higher.x', 'romantic.x', 'famrel.x',\n",
    "       'freetime.x', 'goout.x', 'Dalc.x', 'Walc.x', 'health.x', 'absences.x','G1.x','G3.x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "yfeatures = ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
    "       'Mjob', 'Fjob', 'reason', 'nursery', 'internet','guardian.y', 'traveltime.y', 'studytime.y',\n",
    "       'failures.y', 'schoolsup.y', 'famsup.y', 'paid.y', 'activities.y',\n",
    "       'higher.y', 'romantic.y', 'famrel.y', 'freetime.y', 'goout.y', 'Dalc.y',\n",
    "       'Walc.y', 'health.y', 'absences.y','G1.y','G3.y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keepcol = ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu',\n",
    "       'Fedu', 'Mjob', 'Fjob', 'reason', 'nursery', 'internet', 'guardian.x',\n",
    "       'traveltime.x', 'studytime.x', 'failures.x', 'schoolsup.x', 'famsup.x',\n",
    "       'paid.x', 'activities.x', 'higher.x', 'romantic.x', 'famrel.x',\n",
    "       'freetime.x', 'goout.x', 'Dalc.x', 'Walc.x', 'health.x', 'absences.x',\n",
    "       'G1.x', 'G2.x', 'G3.x', 'guardian.y', 'traveltime.y', 'studytime.y',\n",
    "       'failures.y', 'schoolsup.y', 'famsup.y', 'paid.y', 'activities.y',\n",
    "       'higher.y', 'romantic.y', 'famrel.y', 'freetime.y', 'goout.y', 'Dalc.y',\n",
    "       'Walc.y', 'health.y', 'absences.y', 'G1.y', 'G2.y', 'G3.y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fildf = df.loc[:,keepcol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fildf_x = fildf.loc[:,xfeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fildf_y = fildf.loc[:,yfeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(882, 32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fildf_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(882, 32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fildf_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertmarks(mark):\n",
    "    if mark<10:\n",
    "        return 'F'\n",
    "    elif mark==10 or mark==11:\n",
    "        return 'D'\n",
    "    elif mark==12 or mark==13:\n",
    "        return 'C'\n",
    "    elif mark==14 or mark==15:\n",
    "        return'B'\n",
    "    else:\n",
    "        return 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlist=[]\n",
    "for i in fildf_x['G1.x']:\n",
    "    x = convertmarks(i)\n",
    "    newlist.append(x)\n",
    "fildf_x['New G1'] = newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlist=[]\n",
    "for i in fildf_y['G1.y']:\n",
    "    x = convertmarks(i)\n",
    "    newlist.append(x)\n",
    "fildf_y['New G1'] = newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlist=[]\n",
    "for i in fildf_x['G3.x']:\n",
    "    x = convertmarks(i)\n",
    "    newlist.append(x)\n",
    "fildf_x['New G3'] = newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlist=[]\n",
    "for i in fildf_y['G3.y']:\n",
    "    x = convertmarks(i)\n",
    "    newlist.append(x)\n",
    "fildf_y['New G3'] = newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      C\n",
       "1      D\n",
       "2      C\n",
       "3      D\n",
       "4      C\n",
       "      ..\n",
       "877    C\n",
       "878    B\n",
       "879    C\n",
       "880    C\n",
       "881    C\n",
       "Name: New G3, Length: 882, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fildf_y['New G3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fildf_x['New G1']= label_encoder.fit_transform(fildf_x['New G1'])\n",
    "fildf_y['New G1']= label_encoder.fit_transform(fildf_y['New G1'])\n",
    "fildf_x['New G3']= label_encoder.fit_transform(fildf_x['New G3'])\n",
    "fildf_y['New G3']= label_encoder.fit_transform(fildf_y['New G3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2\n",
       "1      3\n",
       "2      2\n",
       "3      3\n",
       "4      2\n",
       "      ..\n",
       "877    2\n",
       "878    1\n",
       "879    2\n",
       "880    2\n",
       "881    2\n",
       "Name: New G3, Length: 882, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fildf_y['New G3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fildf_x = fildf_x.sample(frac=1,random_state=123)\n",
    "fildf_y = fildf_y.sample(frac=1,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    413\n",
       "4    217\n",
       "3    161\n",
       "1     49\n",
       "0     42\n",
       "Name: New G1, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fildf_x['New G1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    406\n",
       "4    276\n",
       "3     99\n",
       "1     59\n",
       "0     42\n",
       "Name: New G3, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fildf_x['New G3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = fildf_x['New G1'].value_counts().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [fildf_x]\n",
    "lst1=[]\n",
    "for class_index, group in fildf_x.groupby('New G1'):\n",
    "    lst1.append(group.sample(max_size, replace=True))\n",
    "fildf_x_G1 = pd.concat(lst1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    42\n",
       "3    42\n",
       "2    42\n",
       "1    42\n",
       "0    42\n",
       "Name: New G1, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fildf_x_G1['New G1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = fildf_y['New G1'].value_counts().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "print(max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [fildf_y]\n",
    "lst1=[]\n",
    "for class_index, group in fildf_y.groupby('New G1'):\n",
    "    lst1.append(group.sample(max_size, replace=True))\n",
    "fildf_y_G1 = pd.concat(lst1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    36\n",
       "3    36\n",
       "2    36\n",
       "1    36\n",
       "0    36\n",
       "Name: New G1, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fildf_y_G1['New G1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = fildf_x['New G3'].value_counts().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [fildf_x]\n",
    "lst1=[]\n",
    "for class_index, group in fildf_x.groupby('New G3'):\n",
    "    lst1.append(group.sample(max_size, replace=True))\n",
    "fildf_x_G3 = pd.concat(lst1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    42\n",
       "3    42\n",
       "2    42\n",
       "1    42\n",
       "0    42\n",
       "Name: New G3, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fildf_x_G3['New G3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = fildf_y['New G3'].value_counts().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [fildf_y]\n",
    "lst1=[]\n",
    "for class_index, group in fildf_y.groupby('New G3'):\n",
    "    lst1.append(group.sample(max_size, replace=True))\n",
    "fildf_y_G3 = pd.concat(lst1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    46\n",
       "3    46\n",
       "2    46\n",
       "1    46\n",
       "0    46\n",
       "Name: New G3, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fildf_y_G3['New G3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
       "       'Mjob', 'Fjob', 'reason', 'nursery', 'internet', 'guardian.y',\n",
       "       'traveltime.y', 'studytime.y', 'failures.y', 'schoolsup.y', 'famsup.y',\n",
       "       'paid.y', 'activities.y', 'higher.y', 'romantic.y', 'famrel.y',\n",
       "       'freetime.y', 'goout.y', 'Dalc.y', 'Walc.y', 'health.y', 'absences.y',\n",
       "       'G1.y', 'G3.y', 'New G1', 'New G3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fildf_y_G3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "fildf_x_G1 = fildf_x_G1.drop(['G1.x','G3.x'],axis=1)\n",
    "fildf_y_G1 = fildf_y_G1.drop(['G1.y','G3.y'],axis=1)\n",
    "fildf_x_G3 = fildf_x_G3.drop(['G1.x','G3.x'],axis=1)\n",
    "fildf_y_G3 = fildf_y_G3.drop(['G1.y','G3.y'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_x_G3 = fildf_x_G3.drop(['New G1','New G3'],axis=1)\n",
    "features_x_G1 = fildf_x_G1.drop(['New G1','New G3'],axis=1)\n",
    "features_y_G3 = fildf_y_G3.drop(['New G1','New G3'],axis=1)\n",
    "features_y_G1 = fildf_y_G1.drop(['New G1','New G3'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_x_G3 = fildf_x_G3['New G3']\n",
    "target_x_G1 = fildf_x_G1['New G1']\n",
    "target_y_G3 = fildf_y_G3['New G3']\n",
    "target_y_G1 = fildf_y_G1['New G1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_x_G1, X_test_x_G1, y_train_x_G1, y_test_x_G1 = train_test_split(features_x_G1, target_x_G1, test_size=0.25, random_state=0)\n",
    "X_train_y_G1, X_test_y_G1, y_train_y_G1, y_test_y_G1 = train_test_split(features_y_G1, target_y_G1, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_x_G3, X_test_x_G3, y_train_x_G3, y_test_x_G3 = train_test_split(features_x_G3, target_x_G3, test_size=0.25, random_state=0)\n",
    "X_train_y_G3, X_test_y_G3, y_train_y_G3, y_test_y_G3 = train_test_split(features_y_G3, target_y_G3, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_svc = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['linear','rbf', 'poly', 'sigmoid']}\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 10 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='poly',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.36      0.36        11\n",
      "           1       0.36      0.40      0.38        10\n",
      "           2       0.42      0.42      0.42        12\n",
      "           3       0.27      0.38      0.32         8\n",
      "           4       0.75      0.50      0.60        12\n",
      "\n",
      "    accuracy                           0.42        53\n",
      "   macro avg       0.43      0.41      0.42        53\n",
      "weighted avg       0.45      0.42      0.43        53\n",
      "\n",
      "[[4 2 3 0 2]\n",
      " [2 4 3 0 2]\n",
      " [2 1 5 4 0]\n",
      " [3 2 1 3 2]\n",
      " [0 1 0 1 6]]\n",
      "Kappa Score: 0.2697777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    2.5s finished\n"
     ]
    }
   ],
   "source": [
    "#grid_svc_x_G1 = GridSearchCV(SVC(),param_grid = param_grid_svc,refit=True,verbose=2,n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_svc_x_G1 = RandomizedSearchCV(SVC(),param_distributions = param_grid_svc,refit=True,verbose=2,n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_svc_x_G1.fit(X_train_x_G1,y_train_x_G1)\n",
    "print(grid_svc_x_G1.best_estimator_)\n",
    "y_pred_x_G1= grid_svc_x_G1.predict(X_test_x_G1)\n",
    "print(classification_report(y_pred_x_G1,y_test_x_G1,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_x_G1,y_pred_x_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G1,y_test_x_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 10 candidates, totalling 300 fits\n",
      "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
      "    probability=False, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90         9\n",
      "           1       0.27      1.00      0.43         3\n",
      "           2       0.08      1.00      0.15         1\n",
      "           3       0.27      1.00      0.43         3\n",
      "           4       1.00      0.22      0.36        37\n",
      "\n",
      "    accuracy                           0.45        53\n",
      "   macro avg       0.49      0.84      0.45        53\n",
      "weighted avg       0.87      0.45      0.45        53\n",
      "\n",
      "[[ 9  0  0  0  2]\n",
      " [ 0  3  0  0  8]\n",
      " [ 0  0  1  0 11]\n",
      " [ 0  0  0  3  8]\n",
      " [ 0  0  0  0  8]]\n",
      "Kappa Score: 0.34203767123287676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "grid_svc_x_G3 = RandomizedSearchCV(SVC(),param_distributions = param_grid_svc,refit=True,verbose=2,n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_svc_x_G3.fit(X_train_x_G3,y_train_x_G3)\n",
    "print(grid_svc_x_G3.best_estimator_)\n",
    "y_pred_x_G3= grid_svc_x_G3.predict(X_test_x_G3)\n",
    "print(classification_report(y_pred_x_G3,y_test_x_G3,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_x_G3,y_pred_x_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G3,y_test_x_G3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 10 candidates, totalling 300 fits\n",
      "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80         6\n",
      "           1       0.18      0.40      0.25         5\n",
      "           2       0.50      0.21      0.30        14\n",
      "           3       0.50      0.31      0.38        13\n",
      "           4       0.45      0.71      0.56         7\n",
      "\n",
      "    accuracy                           0.44        45\n",
      "   macro avg       0.46      0.53      0.46        45\n",
      "weighted avg       0.48      0.44      0.42        45\n",
      "\n",
      "[[6 0 3 0 0]\n",
      " [0 2 3 5 1]\n",
      " [0 2 3 1 0]\n",
      " [0 1 2 4 1]\n",
      " [0 0 3 3 5]]\n",
      "Kappa Score: 0.31859479103573585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    1.1s finished\n"
     ]
    }
   ],
   "source": [
    "grid_svc_y_G1 = RandomizedSearchCV(SVC(),param_distributions = param_grid_svc,refit=True,verbose=2,n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_svc_y_G1.fit(X_train_y_G1,y_train_y_G1)\n",
    "print(grid_svc_y_G1.best_estimator_)\n",
    "y_pred_y_G1= grid_svc_y_G1.predict(X_test_y_G1)\n",
    "print(classification_report(y_pred_y_G1,y_test_y_G1,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_y_G1,y_pred_y_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G1,y_test_y_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 10 candidates, totalling 300 fits\n",
      "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='linear',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.40      0.40        10\n",
      "           1       0.29      0.18      0.22        11\n",
      "           2       0.43      0.40      0.41        15\n",
      "           3       0.33      0.71      0.45         7\n",
      "           4       0.83      0.67      0.74        15\n",
      "\n",
      "    accuracy                           0.47        58\n",
      "   macro avg       0.46      0.47      0.45        58\n",
      "weighted avg       0.49      0.47      0.46        58\n",
      "\n",
      "[[ 4  3  2  0  1]\n",
      " [ 3  2  2  0  0]\n",
      " [ 2  4  6  2  0]\n",
      " [ 1  2  3  5  4]\n",
      " [ 0  0  2  0 10]]\n",
      "Kappa Score: 0.3320950965824665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "grid_svc_y_G3 = RandomizedSearchCV(SVC(),param_distributions = param_grid_svc,refit=True,verbose=2,n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_svc_y_G3.fit(X_train_y_G3,y_train_y_G3)\n",
    "print(grid_svc_y_G3.best_estimator_)\n",
    "y_pred_y_G3= grid_svc_y_G3.predict(X_test_y_G3)\n",
    "print(metrics.classification_report(y_pred_y_G3,y_test_y_G3,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_y_G3,y_pred_y_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G3,y_test_y_G3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "parameters_gbc = {\n",
    "    \"n_estimators\":[5,50,250,500],\n",
    "    \"max_depth\":[1,3,5,7,9],\n",
    "    \"learning_rate\":[0.01,0.1,1,10,100]\n",
    "}\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 10 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   30.7s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.01, loss='deviance', max_depth=5,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.57      0.44         7\n",
      "           1       0.18      0.33      0.24         6\n",
      "           2       0.33      0.31      0.32        13\n",
      "           3       0.64      0.58      0.61        12\n",
      "           4       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.43        53\n",
      "   macro avg       0.45      0.44      0.43        53\n",
      "weighted avg       0.51      0.43      0.45        53\n",
      "\n",
      "[[4 1 4 1 1]\n",
      " [1 2 4 0 4]\n",
      " [0 2 4 3 3]\n",
      " [2 0 1 7 1]\n",
      " [0 1 0 1 6]]\n",
      "Kappa Score: 0.2958370239149689\n"
     ]
    }
   ],
   "source": [
    "grid_gbc_x_G1 = RandomizedSearchCV(gbc,param_distributions = parameters_gbc,refit=True,verbose=2,n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_gbc_x_G1.fit(X_train_x_G1,y_train_x_G1)\n",
    "print(grid_gbc_x_G1.best_estimator_)\n",
    "y_pred_x_G1= grid_gbc_x_G1.predict(X_test_x_G1)\n",
    "print(classification_report(y_pred_x_G1,y_test_x_G1,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_x_G1,y_pred_x_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G1,y_test_x_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 10 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   50.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.60      0.69        15\n",
      "           1       0.36      0.44      0.40         9\n",
      "           2       0.17      0.20      0.18        10\n",
      "           3       0.36      0.44      0.40         9\n",
      "           4       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.45        53\n",
      "   macro avg       0.47      0.44      0.45        53\n",
      "weighted avg       0.50      0.45      0.47        53\n",
      "\n",
      "[[9 1 0 1 0]\n",
      " [2 4 4 1 0]\n",
      " [3 3 2 2 2]\n",
      " [1 0 3 4 3]\n",
      " [0 1 1 1 5]]\n",
      "Kappa Score: 0.3156723063223509\n"
     ]
    }
   ],
   "source": [
    "grid_gbc_x_G3 = RandomizedSearchCV(gbc,param_distributions = parameters_gbc,refit=True,verbose=2,n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_gbc_x_G3.fit(X_train_x_G3,y_train_x_G3)\n",
    "print(grid_gbc_x_G3.best_estimator_)\n",
    "y_pred_x_G3= grid_gbc_x_G3.predict(X_test_x_G3)\n",
    "print(classification_report(y_pred_x_G3,y_test_x_G3,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_x_G3,y_pred_x_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G3,y_test_x_G3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 10 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 199 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   24.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=9,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=50,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.50      0.57        12\n",
      "           1       0.45      0.62      0.53         8\n",
      "           2       0.50      0.43      0.46         7\n",
      "           3       0.75      0.60      0.67        10\n",
      "           4       0.73      1.00      0.84         8\n",
      "\n",
      "    accuracy                           0.62        45\n",
      "   macro avg       0.62      0.63      0.61        45\n",
      "weighted avg       0.63      0.62      0.62        45\n",
      "\n",
      "[[6 2 1 0 0]\n",
      " [4 5 0 2 0]\n",
      " [2 0 3 1 0]\n",
      " [0 0 2 6 0]\n",
      " [0 1 1 1 8]]\n",
      "Kappa Score: 0.5274861025324274\n"
     ]
    }
   ],
   "source": [
    "grid_gbc_y_G1 = RandomizedSearchCV(gbc,param_distributions = parameters_gbc,refit=True,verbose=2,n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_gbc_y_G1.fit(X_train_y_G1,y_train_y_G1)\n",
    "print(grid_gbc_y_G1.best_estimator_)\n",
    "y_pred_y_G1= grid_gbc_y_G1.predict(X_test_y_G1)\n",
    "print(classification_report(y_pred_y_G1,y_test_y_G1,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_y_G1,y_pred_y_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G1,y_test_y_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 10 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=1, loss='deviance', max_depth=5,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=50,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.50      0.44         8\n",
      "           1       0.57      0.33      0.42        12\n",
      "           2       0.36      0.33      0.34        15\n",
      "           3       0.20      0.38      0.26         8\n",
      "           4       0.75      0.60      0.67        15\n",
      "\n",
      "    accuracy                           0.43        58\n",
      "   macro avg       0.46      0.43      0.43        58\n",
      "weighted avg       0.49      0.43      0.45        58\n",
      "\n",
      "[[4 4 2 0 0]\n",
      " [0 4 1 2 0]\n",
      " [3 3 5 2 1]\n",
      " [1 1 5 3 5]\n",
      " [0 0 2 1 9]]\n",
      "Kappa Score: 0.28847583643122676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    5.6s finished\n"
     ]
    }
   ],
   "source": [
    "grid_gbc_y_G3 = RandomizedSearchCV(gbc,param_distributions = parameters_gbc,refit=True,verbose=2,n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_gbc_y_G3.fit(X_train_y_G3,y_train_y_G3)\n",
    "print(grid_gbc_y_G3.best_estimator_)\n",
    "y_pred_y_G3= grid_gbc_y_G3.predict(X_test_y_G3)\n",
    "print(classification_report(y_pred_y_G3,y_test_y_G3,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_y_G3,y_pred_y_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G3,y_test_y_G3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['l2']\n",
    "c_values = [10, 1.0, 0.1, 0.01]\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.33      0.38        15\n",
      "           1       0.18      0.22      0.20         9\n",
      "           2       0.42      0.42      0.42        12\n",
      "           3       0.18      0.67      0.29         3\n",
      "           4       0.88      0.50      0.64        14\n",
      "\n",
      "    accuracy                           0.40        53\n",
      "   macro avg       0.42      0.43      0.38        53\n",
      "weighted avg       0.50      0.40      0.42        53\n",
      "\n",
      "[[5 2 3 0 1]\n",
      " [3 2 4 0 2]\n",
      " [3 1 5 1 2]\n",
      " [4 3 0 2 2]\n",
      " [0 1 0 0 7]]\n",
      "Kappa Score: 0.24822695035460995\n"
     ]
    }
   ],
   "source": [
    "grid_search_lr_x_G1 = RandomizedSearchCV(estimator=lr, param_distributions=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search_lr_x_G1.fit(X_train_x_G1,y_train_x_G1)\n",
    "print(grid_search_lr_x_G1.best_estimator_)\n",
    "y_pred_x_G1= grid_search_lr_x_G1.predict(X_test_x_G1)\n",
    "print(classification_report(y_pred_x_G1,y_test_x_G1,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_x_G1,y_pred_x_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G1,y_test_x_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.46      0.50        13\n",
      "           1       0.55      0.46      0.50        13\n",
      "           2       0.50      0.50      0.50        12\n",
      "           3       0.27      0.60      0.37         5\n",
      "           4       0.38      0.30      0.33        10\n",
      "\n",
      "    accuracy                           0.45        53\n",
      "   macro avg       0.45      0.46      0.44        53\n",
      "weighted avg       0.48      0.45      0.46        53\n",
      "\n",
      "[[6 3 2 0 0]\n",
      " [1 6 3 0 1]\n",
      " [2 0 6 1 3]\n",
      " [1 3 1 3 3]\n",
      " [3 1 0 1 3]]\n",
      "Kappa Score: 0.31506238859180036\n"
     ]
    }
   ],
   "source": [
    "grid_search_lr_x_G3 = RandomizedSearchCV(estimator=lr, param_distributions=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search_lr_x_G3.fit(X_train_x_G3,y_train_x_G3)\n",
    "print(grid_search_lr_x_G3.best_estimator_)\n",
    "y_pred_x_G3= grid_search_lr_x_G3.predict(X_test_x_G3)\n",
    "print(classification_report(y_pred_x_G3,y_test_x_G3,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_x_G3,y_pred_x_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G3,y_test_x_G3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.50      0.53        10\n",
      "           1       0.64      0.88      0.74         8\n",
      "           2       0.33      0.29      0.31         7\n",
      "           3       0.50      0.40      0.44        10\n",
      "           4       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.56        45\n",
      "   macro avg       0.53      0.55      0.54        45\n",
      "weighted avg       0.54      0.56      0.54        45\n",
      "\n",
      "[[5 0 2 1 1]\n",
      " [1 7 1 2 0]\n",
      " [3 0 2 1 0]\n",
      " [1 1 0 4 2]\n",
      " [0 0 2 2 7]]\n",
      "Kappa Score: 0.44272445820433437\n"
     ]
    }
   ],
   "source": [
    "grid_search_lr_y_G1 = RandomizedSearchCV(estimator=lr, param_distributions=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search_lr_y_G1.fit(X_train_y_G1,y_train_y_G1)\n",
    "print(grid_search_lr_y_G1.best_estimator_)\n",
    "y_pred_y_G1= grid_search_lr_y_G1.predict(X_test_y_G1)\n",
    "print(classification_report(y_pred_y_G1,y_test_y_G1,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_y_G1,y_pred_y_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G1,y_test_y_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.33      0.32         9\n",
      "           1       0.43      0.27      0.33        11\n",
      "           2       0.29      0.33      0.31        12\n",
      "           3       0.40      0.67      0.50         9\n",
      "           4       0.83      0.59      0.69        17\n",
      "\n",
      "    accuracy                           0.45        58\n",
      "   macro avg       0.45      0.44      0.43        58\n",
      "weighted avg       0.49      0.45      0.46        58\n",
      "\n",
      "[[ 3  4  2  0  1]\n",
      " [ 1  3  2  0  1]\n",
      " [ 4  3  4  3  0]\n",
      " [ 1  1  2  6  5]\n",
      " [ 0  0  2  0 10]]\n",
      "Kappa Score: 0.3100371747211895\n"
     ]
    }
   ],
   "source": [
    "grid_search_lr_y_G3 = RandomizedSearchCV(estimator=lr, param_distributions=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search_lr_y_G3.fit(X_train_y_G3,y_train_y_G3)\n",
    "print(grid_search_lr_y_G3.best_estimator_)\n",
    "y_pred_y_G3= grid_search_lr_y_G3.predict(X_test_y_G3)\n",
    "print(classification_report(y_pred_y_G3,y_test_y_G3,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_y_G3,y_pred_y_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G3,y_test_y_G3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models and parameters\n",
    "rf = RandomForestClassifier()\n",
    "n_estimators = [10, 100, 1000]\n",
    "max_features = ['sqrt', 'log2']\n",
    "# define grid search\n",
    "grid = dict(n_estimators=n_estimators,max_features=max_features)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='log2',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.50      0.42         8\n",
      "           1       0.45      0.45      0.45        11\n",
      "           2       0.50      0.43      0.46        14\n",
      "           3       0.36      0.57      0.44         7\n",
      "           4       0.88      0.54      0.67        13\n",
      "\n",
      "    accuracy                           0.49        53\n",
      "   macro avg       0.51      0.50      0.49        53\n",
      "weighted avg       0.54      0.49      0.50        53\n",
      "\n",
      "[[4 3 3 1 0]\n",
      " [1 5 3 0 2]\n",
      " [1 0 6 2 3]\n",
      " [2 2 2 4 1]\n",
      " [0 1 0 0 7]]\n",
      "Kappa Score: 0.36428254109284763\n"
     ]
    }
   ],
   "source": [
    "grid_search_rf_x_G1 = RandomizedSearchCV(estimator=rf, param_distributions=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search_rf_x_G1.fit(X_train_x_G1,y_train_x_G1)\n",
    "print(grid_search_rf_x_G1.best_estimator_)\n",
    "y_pred_x_G1= grid_search_rf_x_G1.predict(X_test_x_G1)\n",
    "print(classification_report(y_pred_x_G1,y_test_x_G1,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_x_G1,y_pred_x_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G1,y_test_x_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='sqrt',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.62      0.74        16\n",
      "           1       0.45      0.56      0.50         9\n",
      "           2       0.17      0.29      0.21         7\n",
      "           3       0.45      0.62      0.53         8\n",
      "           4       0.88      0.54      0.67        13\n",
      "\n",
      "    accuracy                           0.55        53\n",
      "   macro avg       0.57      0.53      0.53        53\n",
      "weighted avg       0.66      0.55      0.58        53\n",
      "\n",
      "[[10  1  0  0  0]\n",
      " [ 2  5  3  1  0]\n",
      " [ 4  2  2  2  2]\n",
      " [ 0  0  2  5  4]\n",
      " [ 0  1  0  0  7]]\n",
      "Kappa Score: 0.4366696191319752\n"
     ]
    }
   ],
   "source": [
    "grid_search_rf_x_G3 = RandomizedSearchCV(estimator=rf, param_distributions=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search_rf_x_G3.fit(X_train_x_G3,y_train_x_G3)\n",
    "print(grid_search_rf_x_G3.best_estimator_)\n",
    "y_pred_x_G3= grid_search_rf_x_G3.predict(X_test_x_G3)\n",
    "print(classification_report(y_pred_x_G3,y_test_x_G3,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_x_G3,y_pred_x_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G3,y_test_x_G3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='log2',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.67      0.76        12\n",
      "           1       0.36      0.50      0.42         8\n",
      "           2       0.33      0.20      0.25        10\n",
      "           3       0.62      0.62      0.62         8\n",
      "           4       0.64      1.00      0.78         7\n",
      "\n",
      "    accuracy                           0.58        45\n",
      "   macro avg       0.57      0.60      0.57        45\n",
      "weighted avg       0.59      0.58      0.57        45\n",
      "\n",
      "[[8 0 1 0 0]\n",
      " [3 4 4 0 0]\n",
      " [1 3 2 0 0]\n",
      " [0 1 2 5 0]\n",
      " [0 0 1 3 7]]\n",
      "Kappa Score: 0.47481572481572476\n"
     ]
    }
   ],
   "source": [
    "grid_search_rf_y_G1 = RandomizedSearchCV(estimator=rf, param_distributions=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search_rf_y_G1.fit(X_train_y_G1,y_train_y_G1)\n",
    "print(grid_search_rf_y_G1.best_estimator_)\n",
    "y_pred_y_G1= grid_search_rf_y_G1.predict(X_test_y_G1)\n",
    "print(classification_report(y_pred_y_G1,y_test_y_G1,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_y_G1,y_pred_y_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G1,y_test_y_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='log2',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.50      0.37         6\n",
      "           1       0.57      0.29      0.38        14\n",
      "           2       0.29      0.33      0.31        12\n",
      "           3       0.40      0.75      0.52         8\n",
      "           4       0.92      0.61      0.73        18\n",
      "\n",
      "    accuracy                           0.48        58\n",
      "   macro avg       0.49      0.50      0.46        58\n",
      "weighted avg       0.57      0.48      0.49        58\n",
      "\n",
      "[[ 3  4  2  1  0]\n",
      " [ 1  4  2  0  0]\n",
      " [ 2  5  4  0  3]\n",
      " [ 0  1  4  6  4]\n",
      " [ 0  0  0  1 11]]\n",
      "Kappa Score: 0.35603256846780174\n"
     ]
    }
   ],
   "source": [
    "grid_search_rf_y_G3 = RandomizedSearchCV(estimator=rf, param_distributions=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search_rf_y_G3.fit(X_train_y_G3,y_train_y_G3)\n",
    "print(grid_search_rf_y_G3.best_estimator_)\n",
    "y_pred_y_G3= grid_search_rf_y_G3.predict(X_test_y_G3)\n",
    "print(classification_report(y_pred_y_G3,y_test_y_G3,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_y_G3,y_pred_y_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G3,y_test_y_G3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = DecisionTreeClassifier()\n",
    "param_dist = {\"max_depth\": [1,2,3,4,5],\n",
    "              \"max_features\": ['auto', 'sqrt', 'log2'],\n",
    "              \"min_samples_leaf\": [1,2,3,4,5],\n",
    "              \"min_samples_split\" : [1,2,3,4,5],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.39      0.48        18\n",
      "           1       0.64      0.41      0.50        17\n",
      "           2       0.08      0.33      0.13         3\n",
      "           3       0.36      0.67      0.47         6\n",
      "           4       0.75      0.67      0.71         9\n",
      "\n",
      "    accuracy                           0.47        53\n",
      "   macro avg       0.49      0.49      0.46        53\n",
      "weighted avg       0.59      0.47      0.51        53\n",
      "\n",
      "[[7 2 1 1 0]\n",
      " [1 7 1 0 2]\n",
      " [5 5 1 1 0]\n",
      " [4 2 0 4 1]\n",
      " [1 1 0 0 6]]\n",
      "Kappa Score: 0.34044444444444444\n"
     ]
    }
   ],
   "source": [
    "grid_search_dct_x_G1 = RandomizedSearchCV(estimator=dct, param_distributions=param_dist, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search_dct_x_G1.fit(X_train_x_G1,y_train_x_G1)\n",
    "print(grid_search_dct_x_G1.best_estimator_)\n",
    "y_pred_x_G1= grid_search_dct_x_G1.predict(X_test_x_G1)\n",
    "print(classification_report(y_pred_x_G1,y_test_x_G1,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_x_G1,y_pred_x_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G1,y_test_x_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=4, max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=3,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.31      0.33        13\n",
      "           1       0.64      0.37      0.47        19\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.45      0.31      0.37        16\n",
      "           4       0.12      0.20      0.15         5\n",
      "\n",
      "    accuracy                           0.32        53\n",
      "   macro avg       0.32      0.24      0.26        53\n",
      "weighted avg       0.47      0.32      0.38        53\n",
      "\n",
      "[[4 4 0 3 0]\n",
      " [0 7 0 2 2]\n",
      " [7 1 0 4 0]\n",
      " [1 3 0 5 2]\n",
      " [1 4 0 2 1]]\n",
      "Kappa Score: 0.14859437751004012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "grid_search_dct_x_G3 = RandomizedSearchCV(estimator=dct, param_distributions=param_dist, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search_dct_x_G3.fit(X_train_x_G3,y_train_x_G3)\n",
    "print(grid_search_dct_x_G3.best_estimator_)\n",
    "y_pred_x_G3= grid_search_dct_x_G3.predict(X_test_x_G3)\n",
    "print(classification_report(y_pred_x_G3,y_test_x_G3,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_x_G3,y_pred_x_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G3,y_test_x_G3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features='log2', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=5, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.40      0.42        10\n",
      "           1       0.36      0.31      0.33        13\n",
      "           2       0.50      0.21      0.30        14\n",
      "           3       0.12      0.20      0.15         5\n",
      "           4       0.27      1.00      0.43         3\n",
      "\n",
      "    accuracy                           0.33        45\n",
      "   macro avg       0.34      0.42      0.33        45\n",
      "weighted avg       0.39      0.33      0.33        45\n",
      "\n",
      "[[4 3 2 0 0]\n",
      " [3 4 2 2 0]\n",
      " [1 2 3 0 0]\n",
      " [2 3 2 1 0]\n",
      " [0 1 5 2 3]]\n",
      "Kappa Score: 0.17431192660550443\n"
     ]
    }
   ],
   "source": [
    "grid_search_dct_y_G1 = RandomizedSearchCV(estimator=dct, param_distributions=param_dist, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search_dct_y_G1.fit(X_train_y_G1,y_train_y_G1)\n",
    "print(grid_search_dct_y_G1.best_estimator_)\n",
    "y_pred_y_G1= grid_search_dct_y_G1.predict(X_test_y_G1)\n",
    "print(classification_report(y_pred_y_G1,y_test_y_G1,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_y_G1,y_pred_y_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G1,y_test_y_G1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
      "                       max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=4, min_samples_split=5,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.50      0.37         6\n",
      "           1       0.57      0.29      0.38        14\n",
      "           2       0.29      0.33      0.31        12\n",
      "           3       0.40      0.75      0.52         8\n",
      "           4       0.92      0.61      0.73        18\n",
      "\n",
      "    accuracy                           0.48        58\n",
      "   macro avg       0.49      0.50      0.46        58\n",
      "weighted avg       0.57      0.48      0.49        58\n",
      "\n",
      "[[ 3  4  2  1  0]\n",
      " [ 1  4  2  0  0]\n",
      " [ 2  5  4  0  3]\n",
      " [ 0  1  4  6  4]\n",
      " [ 0  0  0  1 11]]\n",
      "Kappa Score: 0.35603256846780174\n"
     ]
    }
   ],
   "source": [
    "grid_search_dct_y_G3 = RandomizedSearchCV(estimator=dct, param_distributions=param_dist, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search_dct_y_G3.fit(X_train_y_G3,y_train_y_G3)\n",
    "print(grid_search_dct_y_G3.best_estimator_)\n",
    "y_pred_y_G3= grid_search_rf_y_G3.predict(X_test_y_G3)\n",
    "print(classification_report(y_pred_y_G3,y_test_y_G3,zero_division='warn'))\n",
    "print(confusion_matrix(y_test_y_G3,y_pred_y_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G3,y_test_y_G3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.17      0.12         6\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.67      0.24      0.36        33\n",
      "           3       0.27      0.60      0.37         5\n",
      "           4       0.62      0.62      0.62         8\n",
      "\n",
      "    accuracy                           0.32        53\n",
      "   macro avg       0.33      0.33      0.29        53\n",
      "weighted avg       0.55      0.32      0.36        53\n",
      "\n",
      "Kappa Score: 0.13937753721244928\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_x_G1,y_train_x_G1)\n",
    "y_pred_x_G1= clf.predict(X_test_x_G1)\n",
    "print(classification_report(y_pred_x_G1,y_test_x_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G1,y_test_x_G1)))\n",
    "probagnbG1x = clf.predict_proba(X_test_x_G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.27      0.42        41\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.08      1.00      0.15         1\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.12      0.14      0.13         7\n",
      "\n",
      "    accuracy                           0.25        53\n",
      "   macro avg       0.24      0.28      0.14        53\n",
      "weighted avg       0.79      0.25      0.35        53\n",
      "\n",
      "Kappa Score: 0.056099732858414963\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_x_G3,y_train_x_G3)\n",
    "y_pred_x_G3= clf.predict(X_test_x_G3)\n",
    "print(classification_report(y_pred_x_G3,y_test_x_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_x_G3,y_test_x_G3)))\n",
    "probagnbG3x = clf.predict_proba(X_test_x_G3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.20      0.14         5\n",
      "           1       1.00      0.42      0.59        26\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.12      0.33      0.18         3\n",
      "           4       0.36      1.00      0.53         4\n",
      "\n",
      "    accuracy                           0.38        45\n",
      "   macro avg       0.32      0.39      0.29        45\n",
      "weighted avg       0.63      0.38      0.42        45\n",
      "\n",
      "Kappa Score: 0.20454545454545459\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_y_G1,y_train_y_G1)\n",
    "y_pred_y_G1 = clf.predict(X_test_y_G1)\n",
    "print(classification_report(y_pred_y_G1,y_test_y_G1))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G1,y_test_y_G1)))\n",
    "probagnbG1y = clf.predict_proba(X_test_y_G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.11      0.14        18\n",
      "           1       0.71      0.21      0.32        24\n",
      "           2       0.07      0.10      0.08        10\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.33      0.67      0.44         6\n",
      "\n",
      "    accuracy                           0.21        58\n",
      "   macro avg       0.26      0.22      0.20        58\n",
      "weighted avg       0.40      0.21      0.24        58\n",
      "\n",
      "Kappa Score: 0.048502139800285504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_y_G3,y_train_y_G3)\n",
    "y_pred_y_G3 = clf.predict(X_test_y_G3)\n",
    "print(classification_report(y_pred_y_G3,y_test_y_G3))\n",
    "print(\"Kappa Score: \" +str(cohen_kappa_score(y_pred_y_G3,y_test_y_G3)))\n",
    "probagnbG3y = clf.predict_proba(X_test_y_G3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
